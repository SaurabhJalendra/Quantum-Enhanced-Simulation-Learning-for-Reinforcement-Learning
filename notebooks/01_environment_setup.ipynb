{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Environment Setup & Foundation\n",
    "\n",
    "**Notebook:** `01_environment_setup.ipynb`  \n",
    "**Phase:** 1 of 9  \n",
    "**Purpose:** Verify environment setup, configure GPU, create utility functions, and test basic RL environments  \n",
    "**Author:** Saurabh Jalendra  \n",
    "**Institution:** BITS Pilani (WILP Division)  \n",
    "**Date:** November 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [System Information](#1-system-information)\n",
    "2. [Package Imports & Verification](#2-package-imports--verification)\n",
    "3. [GPU Configuration](#3-gpu-configuration)\n",
    "4. [Reproducibility Setup](#4-reproducibility-setup)\n",
    "5. [Utility Functions](#5-utility-functions)\n",
    "6. [Environment Testing](#6-environment-testing)\n",
    "7. [Visualization Helpers](#7-visualization-helpers)\n",
    "8. [Summary & Next Steps](#8-summary--next-steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. System Information\n",
    "\n",
    "First, let's verify the system configuration and hardware availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell: System Information\n",
    "Purpose: Display system configuration and verify hardware\n",
    "\"\"\"\n",
    "\n",
    "import platform\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"QUANTUM-ENHANCED WORLD MODELS - ENVIRONMENT SETUP\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nDate: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"\\nSystem Information:\")\n",
    "print(f\"  Python Version: {sys.version}\")\n",
    "print(f\"  Platform: {platform.platform()}\")\n",
    "print(f\"  Processor: {platform.processor()}\")\n",
    "print(f\"  Machine: {platform.machine()}\")\n",
    "print(f\"  Working Directory: {os.getcwd()}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Package Imports & Verification\n",
    "\n",
    "Import all required packages and verify versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell: Core Package Imports\n",
    "Purpose: Import and verify core scientific computing packages\n",
    "\"\"\"\n",
    "\n",
    "# Core scientific computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "print(\"Core Scientific Computing:\")\n",
    "print(f\"  NumPy: {np.__version__}\")\n",
    "print(f\"  Pandas: {pd.__version__}\")\n",
    "print(f\"  SciPy: {scipy.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell: PyTorch Import & Verification\n",
    "Purpose: Import PyTorch and verify GPU availability\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "print(\"PyTorch Configuration:\")\n",
    "print(f\"  PyTorch Version: {torch.__version__}\")\n",
    "print(f\"  CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"  cuDNN Version: {torch.backends.cudnn.version()}\")\n",
    "    print(f\"  GPU Count: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        props = torch.cuda.get_device_properties(i)\n",
    "        print(f\"  GPU {i}: {props.name}\")\n",
    "        print(f\"    - Memory: {props.total_memory / 1024**3:.1f} GB\")\n",
    "        print(f\"    - Compute Capability: {props.major}.{props.minor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell: Visualization Package Imports\n",
    "Purpose: Import visualization libraries\n",
    "\"\"\"\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Visualization:\")\n",
    "print(f\"  Matplotlib: {plt.matplotlib.__version__}\")\n",
    "print(f\"  Seaborn: {sns.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell: Gymnasium Import & Verification\n",
    "Purpose: Import and verify Gymnasium RL library\n",
    "\"\"\"\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "print(\"Reinforcement Learning:\")\n",
    "print(f\"  Gymnasium: {gym.__version__}\")\n",
    "\n",
    "# List available environments\n",
    "classic_envs = [env for env in gym.envs.registry.keys() if 'CartPole' in env or 'Pendulum' in env]\n",
    "print(f\"  Classic Control Environments Available: {len(classic_envs)}\")\n",
    "for env in classic_envs[:5]:\n",
    "    print(f\"    - {env}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell: DMControl Import (Optional)\n",
    "Purpose: Try to import DMControl Suite\n",
    "\"\"\"\n",
    "\n",
    "DMCONTROL_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    from dm_control import suite\n",
    "    import mujoco\n",
    "    DMCONTROL_AVAILABLE = True\n",
    "    print(\"DMControl Suite:\")\n",
    "    print(f\"  MuJoCo Version: {mujoco.__version__}\")\n",
    "    print(f\"  Available domains: {suite.BENCHMARKING}\")\n",
    "except ImportError as e:\n",
    "    print(f\"DMControl Suite: NOT AVAILABLE\")\n",
    "    print(f\"  Error: {e}\")\n",
    "    print(\"  Note: DMControl is optional for Phase 1. Install with:\")\n",
    "    print(\"        pip install dm-control mujoco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell: Additional Package Imports\n",
    "Purpose: Import remaining utility packages\n",
    "\"\"\"\n",
    "\n",
    "from typing import Dict, List, Tuple, Optional, Union, Any, Callable\n",
    "from dataclasses import dataclass, field\n",
    "from collections import deque, defaultdict\n",
    "import warnings\n",
    "import time\n",
    "import json\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "print(\"\\nAll core packages imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. GPU Configuration\n",
    "\n",
    "Configure GPU settings for optimal performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell: Device Configuration\n",
    "Purpose: Set up compute device (GPU/CPU) with optimal settings\n",
    "\"\"\"\n",
    "\n",
    "def get_device(prefer_gpu: bool = True) -> torch.device:\n",
    "    \"\"\"\n",
    "    Get the best available compute device.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    prefer_gpu : bool\n",
    "        Whether to prefer GPU over CPU if available\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    torch.device\n",
    "        The selected compute device\n",
    "    \"\"\"\n",
    "    if prefer_gpu and torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        # Enable cuDNN auto-tuner for optimal performance\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        # Enable TF32 for better performance on Ampere+ GPUs\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    \n",
    "    return device\n",
    "\n",
    "\n",
    "# Set global device\n",
    "DEVICE = get_device()\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "if DEVICE.type == \"cuda\":\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    print(f\"cuDNN Benchmark: {torch.backends.cudnn.benchmark}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell: GPU Memory Test\n",
    "Purpose: Test GPU memory and compute capability\n",
    "\"\"\"\n",
    "\n",
    "def test_gpu_compute() -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Test GPU compute capability with a simple matrix multiplication.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, Any]\n",
    "        Test results including time and memory usage\n",
    "    \"\"\"\n",
    "    results = {\"device\": str(DEVICE)}\n",
    "    \n",
    "    # Test matrix size\n",
    "    size = 4096\n",
    "    \n",
    "    # Create random matrices\n",
    "    a = torch.randn(size, size, device=DEVICE)\n",
    "    b = torch.randn(size, size, device=DEVICE)\n",
    "    \n",
    "    # Warmup\n",
    "    for _ in range(3):\n",
    "        _ = torch.mm(a, b)\n",
    "    \n",
    "    if DEVICE.type == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    # Timed run\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(10):\n",
    "        c = torch.mm(a, b)\n",
    "    \n",
    "    if DEVICE.type == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    elapsed = (time.perf_counter() - start) / 10\n",
    "    \n",
    "    results[\"matrix_size\"] = size\n",
    "    results[\"time_per_matmul_ms\"] = elapsed * 1000\n",
    "    results[\"tflops\"] = (2 * size**3) / elapsed / 1e12\n",
    "    \n",
    "    if DEVICE.type == \"cuda\":\n",
    "        results[\"gpu_memory_allocated_mb\"] = torch.cuda.memory_allocated() / 1024**2\n",
    "        results[\"gpu_memory_cached_mb\"] = torch.cuda.memory_reserved() / 1024**2\n",
    "    \n",
    "    # Cleanup\n",
    "    del a, b, c\n",
    "    if DEVICE.type == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Run GPU test\n",
    "gpu_results = test_gpu_compute()\n",
    "print(\"GPU Compute Test Results:\")\n",
    "for key, value in gpu_results.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Reproducibility Setup\n",
    "\n",
    "Set up seeds and deterministic settings for reproducible experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell: Reproducibility Functions\n",
    "Purpose: Create functions for setting random seeds\n",
    "\"\"\"\n",
    "\n",
    "def set_seed(seed: int = 42, deterministic: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Set random seeds for reproducibility across all libraries.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    seed : int\n",
    "        Random seed value\n",
    "    deterministic : bool\n",
    "        Whether to enable deterministic algorithms (may reduce performance)\n",
    "    \"\"\"\n",
    "    import random\n",
    "    \n",
    "    # Python random\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # NumPy\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # For multi-GPU\n",
    "    \n",
    "    if deterministic:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        # PyTorch 1.8+ deterministic algorithms\n",
    "        if hasattr(torch, 'use_deterministic_algorithms'):\n",
    "            try:\n",
    "                torch.use_deterministic_algorithms(True)\n",
    "            except RuntimeError:\n",
    "                # Some operations don't have deterministic implementations\n",
    "                pass\n",
    "    \n",
    "    # Environment variable for CUDA determinism\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "\n",
    "# Set default seed\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "print(f\"Random seed set to: {SEED}\")\n",
    "print(f\"Deterministic mode: enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell: Verify Reproducibility\n",
    "Purpose: Test that random number generation is reproducible\n",
    "\"\"\"\n",
    "\n",
    "def verify_reproducibility(seed: int = 42) -> bool:\n",
    "    \"\"\"\n",
    "    Verify that setting the seed produces reproducible results.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    seed : int\n",
    "        Seed to test\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if results are reproducible\n",
    "    \"\"\"\n",
    "    # First run\n",
    "    set_seed(seed)\n",
    "    np_result1 = np.random.rand(5)\n",
    "    torch_result1 = torch.rand(5)\n",
    "    \n",
    "    # Second run\n",
    "    set_seed(seed)\n",
    "    np_result2 = np.random.rand(5)\n",
    "    torch_result2 = torch.rand(5)\n",
    "    \n",
    "    np_match = np.allclose(np_result1, np_result2)\n",
    "    torch_match = torch.allclose(torch_result1, torch_result2)\n",
    "    \n",
    "    return np_match and torch_match\n",
    "\n",
    "\n",
    "reproducible = verify_reproducibility(SEED)\n",
    "print(f\"Reproducibility verified: {reproducible}\")\n",
    "if not reproducible:\n",
    "    print(\"WARNING: Results may not be reproducible!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Utility Functions\n",
    "\n",
    "Create utility functions for logging, timing, and common operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell: Logging Utilities\n",
    "Purpose: Create logging helper functions\n",
    "\"\"\"\n",
    "\n",
    "@dataclass\n",
    "class MetricLogger:\n",
    "    \"\"\"\n",
    "    Simple metric logger for tracking training progress.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    name : str\n",
    "        Name of the logger\n",
    "    metrics : Dict[str, List[float]]\n",
    "        Dictionary of metric names to values\n",
    "    \"\"\"\n",
    "    name: str\n",
    "    metrics: Dict[str, List[float]] = field(default_factory=lambda: defaultdict(list))\n",
    "    \n",
    "    def log(self, **kwargs) -> None:\n",
    "        \"\"\"Log metric values.\"\"\"\n",
    "        for key, value in kwargs.items():\n",
    "            self.metrics[key].append(value)\n",
    "    \n",
    "    def get(self, key: str) -> List[float]:\n",
    "        \"\"\"Get all values for a metric.\"\"\"\n",
    "        return self.metrics[key]\n",
    "    \n",
    "    def get_last(self, key: str, n: int = 1) -> Union[float, List[float]]:\n",
    "        \"\"\"Get last n values for a metric.\"\"\"\n",
    "        values = self.metrics[key][-n:]\n",
    "        return values[0] if n == 1 else values\n",
    "    \n",
    "    def get_mean(self, key: str, n: Optional[int] = None) -> float:\n",
    "        \"\"\"Get mean of last n values (or all if n is None).\"\"\"\n",
    "        values = self.metrics[key]\n",
    "        if n is not None:\n",
    "            values = values[-n:]\n",
    "        return np.mean(values) if values else 0.0\n",
    "    \n",
    "    def to_dataframe(self) -> pd.DataFrame:\n",
    "        \"\"\"Convert metrics to a pandas DataFrame.\"\"\"\n",
    "        return pd.DataFrame(dict(self.metrics))\n",
    "    \n",
    "    def save(self, path: Union[str, Path]) -> None:\n",
    "        \"\"\"Save metrics to CSV file.\"\"\"\n",
    "        self.to_dataframe().to_csv(path, index=False)\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"MetricLogger(name='{self.name}', metrics={list(self.metrics.keys())})\"\n",
    "\n",
    "\n",
    "# Test the logger\n",
    "test_logger = MetricLogger(name=\"test\")\n",
    "for i in range(10):\n",
    "    test_logger.log(loss=1.0/(i+1), reward=i*10)\n",
    "\n",
    "print(f\"Logger: {test_logger}\")\n",
    "print(f\"Mean loss: {test_logger.get_mean('loss'):.4f}\")\n",
    "print(f\"Last 3 rewards: {test_logger.get_last('reward', 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell: Timing Utilities\n",
    "Purpose: Create timing helper functions and context managers\n",
    "\"\"\"\n",
    "\n",
    "import contextlib\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def timer(name: str = \"Operation\"):\n",
    "    \"\"\"\n",
    "    Context manager for timing code blocks.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    name : str\n",
    "        Name of the operation being timed\n",
    "    \n",
    "    Yields\n",
    "    ------\n",
    "    Dict with timing info\n",
    "    \"\"\"\n",
    "    start = time.perf_counter()\n",
    "    timing_info = {\"name\": name}\n",
    "    try:\n",
    "        yield timing_info\n",
    "    finally:\n",
    "        elapsed = time.perf_counter() - start\n",
    "        timing_info[\"elapsed\"] = elapsed\n",
    "        print(f\"{name}: {elapsed:.4f}s\")\n",
    "\n",
    "\n",
    "class Timer:\n",
    "    \"\"\"\n",
    "    Reusable timer class for tracking multiple operations.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> t = Timer()\n",
    "    >>> t.start()\n",
    "    >>> # ... do something ...\n",
    "    >>> elapsed = t.stop()\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._start_time = None\n",
    "        self._elapsed = 0.0\n",
    "        self._running = False\n",
    "    \n",
    "    def start(self) -> 'Timer':\n",
    "        \"\"\"Start the timer.\"\"\"\n",
    "        if not self._running:\n",
    "            self._start_time = time.perf_counter()\n",
    "            self._running = True\n",
    "        return self\n",
    "    \n",
    "    def stop(self) -> float:\n",
    "        \"\"\"Stop the timer and return elapsed time.\"\"\"\n",
    "        if self._running:\n",
    "            self._elapsed = time.perf_counter() - self._start_time\n",
    "            self._running = False\n",
    "        return self._elapsed\n",
    "    \n",
    "    def reset(self) -> 'Timer':\n",
    "        \"\"\"Reset the timer.\"\"\"\n",
    "        self._start_time = None\n",
    "        self._elapsed = 0.0\n",
    "        self._running = False\n",
    "        return self\n",
    "    \n",
    "    @property\n",
    "    def elapsed(self) -> float:\n",
    "        \"\"\"Get elapsed time.\"\"\"\n",
    "        if self._running:\n",
    "            return time.perf_counter() - self._start_time\n",
    "        return self._elapsed\n",
    "\n",
    "\n",
    "# Test timing utilities\n",
    "with timer(\"Test computation\"):\n",
    "    _ = torch.randn(1000, 1000, device=DEVICE) @ torch.randn(1000, 1000, device=DEVICE)\n",
    "    if DEVICE.type == \"cuda\":\n",
    "        torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell: Configuration Utilities\n",
    "Purpose: Load and manage configuration files\n",
    "\"\"\"\n",
    "\n",
    "def load_config(path: Union[str, Path]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Load configuration from YAML file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path : Union[str, Path]\n",
    "        Path to YAML configuration file\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, Any]\n",
    "        Configuration dictionary\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Config file not found: {path}\")\n",
    "    \n",
    "    with open(path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    return config\n",
    "\n",
    "\n",
    "def save_config(config: Dict[str, Any], path: Union[str, Path]) -> None:\n",
    "    \"\"\"\n",
    "    Save configuration to YAML file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    config : Dict[str, Any]\n",
    "        Configuration dictionary\n",
    "    path : Union[str, Path]\n",
    "        Path to save YAML file\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with open(path, 'w') as f:\n",
    "        yaml.dump(config, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "\n",
    "# Test config loading\n",
    "try:\n",
    "    config_path = Path(\"../configs/default.yaml\")\n",
    "    if config_path.exists():\n",
    "        config = load_config(config_path)\n",
    "        print(\"Loaded default configuration:\")\n",
    "        print(f\"  Environment: {config.get('environment', {}).get('name', 'N/A')}\")\n",
    "        print(f\"  Seed: {config.get('seed', 'N/A')}\")\n",
    "        print(f\"  Device: {config.get('device', 'N/A')}\")\n",
    "    else:\n",
    "        print(f\"Config file not found at {config_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading config: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell: Path Utilities\n",
    "Purpose: Helper functions for project paths\n",
    "\"\"\"\n",
    "\n",
    "def get_project_root() -> Path:\n",
    "    \"\"\"\n",
    "    Get the project root directory.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Path\n",
    "        Path to project root\n",
    "    \"\"\"\n",
    "    # Navigate up from notebooks directory\n",
    "    current = Path.cwd()\n",
    "    while current.name != \"Quantum-Enhanced-Simulation-Learning-for-Reinforcement-Learning\" and current.parent != current:\n",
    "        current = current.parent\n",
    "    return current\n",
    "\n",
    "\n",
    "PROJECT_ROOT = get_project_root()\n",
    "NOTEBOOKS_DIR = PROJECT_ROOT / \"notebooks\"\n",
    "SRC_DIR = PROJECT_ROOT / \"src\"\n",
    "CONFIGS_DIR = PROJECT_ROOT / \"configs\"\n",
    "EXPERIMENTS_DIR = PROJECT_ROOT / \"experiments\"\n",
    "FIGURES_DIR = PROJECT_ROOT / \"figures\"\n",
    "\n",
    "print(f\"Project Root: {PROJECT_ROOT}\")\n",
    "print(f\"Source Dir: {SRC_DIR}\")\n",
    "print(f\"Configs Dir: {CONFIGS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Environment Testing\n",
    "\n",
    "Test the RL environments to ensure they work correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell: CartPole Environment Test\n",
    "Purpose: Test CartPole-v1 environment\n",
    "\"\"\"\n",
    "\n",
    "def test_environment(env_name: str, num_episodes: int = 3, max_steps: int = 100) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Test a Gymnasium environment with random actions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    env_name : str\n",
    "        Name of the Gymnasium environment\n",
    "    num_episodes : int\n",
    "        Number of episodes to run\n",
    "    max_steps : int\n",
    "        Maximum steps per episode\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, Any]\n",
    "        Test results including observations, actions, rewards\n",
    "    \"\"\"\n",
    "    env = gym.make(env_name)\n",
    "    \n",
    "    results = {\n",
    "        \"env_name\": env_name,\n",
    "        \"observation_space\": str(env.observation_space),\n",
    "        \"action_space\": str(env.action_space),\n",
    "        \"episodes\": [],\n",
    "    }\n",
    "    \n",
    "    for ep in range(num_episodes):\n",
    "        obs, info = env.reset(seed=SEED + ep)\n",
    "        episode_data = {\n",
    "            \"episode\": ep,\n",
    "            \"observations\": [obs],\n",
    "            \"actions\": [],\n",
    "            \"rewards\": [],\n",
    "            \"total_reward\": 0.0,\n",
    "            \"steps\": 0,\n",
    "        }\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "            action = env.action_space.sample()\n",
    "            obs, reward, terminated, truncated, info = env.step(action)\n",
    "            \n",
    "            episode_data[\"actions\"].append(action)\n",
    "            episode_data[\"rewards\"].append(reward)\n",
    "            episode_data[\"observations\"].append(obs)\n",
    "            episode_data[\"total_reward\"] += reward\n",
    "            episode_data[\"steps\"] = step + 1\n",
    "            \n",
    "            if terminated or truncated:\n",
    "                break\n",
    "        \n",
    "        results[\"episodes\"].append(episode_data)\n",
    "    \n",
    "    env.close()\n",
    "    return results\n",
    "\n",
    "\n",
    "# Test CartPole\n",
    "print(\"Testing CartPole-v1 Environment:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "cartpole_results = test_environment(\"CartPole-v1\", num_episodes=3, max_steps=200)\n",
    "\n",
    "print(f\"Observation Space: {cartpole_results['observation_space']}\")\n",
    "print(f\"Action Space: {cartpole_results['action_space']}\")\n",
    "print(\"\\nEpisode Results:\")\n",
    "for ep_data in cartpole_results[\"episodes\"]:\n",
    "    print(f\"  Episode {ep_data['episode']}: {ep_data['steps']} steps, reward = {ep_data['total_reward']:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell: Pendulum Environment Test\n",
    "Purpose: Test Pendulum-v1 environment (continuous action space)\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nTesting Pendulum-v1 Environment:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "pendulum_results = test_environment(\"Pendulum-v1\", num_episodes=3, max_steps=100)\n",
    "\n",
    "print(f\"Observation Space: {pendulum_results['observation_space']}\")\n",
    "print(f\"Action Space: {pendulum_results['action_space']}\")\n",
    "print(\"\\nEpisode Results:\")\n",
    "for ep_data in pendulum_results[\"episodes\"]:\n",
    "    print(f\"  Episode {ep_data['episode']}: {ep_data['steps']} steps, reward = {ep_data['total_reward']:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell: Experience Collection\n",
    "Purpose: Collect experience tuples for world model training\n",
    "\"\"\"\n",
    "\n",
    "@dataclass\n",
    "class Experience:\n",
    "    \"\"\"\n",
    "    Single experience tuple (s, a, r, s', done).\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    observation : np.ndarray\n",
    "        Current observation\n",
    "    action : Union[int, np.ndarray]\n",
    "        Action taken\n",
    "    reward : float\n",
    "        Reward received\n",
    "    next_observation : np.ndarray\n",
    "        Next observation\n",
    "    done : bool\n",
    "        Whether episode terminated\n",
    "    \"\"\"\n",
    "    observation: np.ndarray\n",
    "    action: Union[int, np.ndarray]\n",
    "    reward: float\n",
    "    next_observation: np.ndarray\n",
    "    done: bool\n",
    "\n",
    "\n",
    "def collect_experiences(\n",
    "    env_name: str,\n",
    "    num_steps: int = 1000,\n",
    "    seed: int = 42\n",
    ") -> List[Experience]:\n",
    "    \"\"\"\n",
    "    Collect experience tuples from an environment.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    env_name : str\n",
    "        Name of the environment\n",
    "    num_steps : int\n",
    "        Number of steps to collect\n",
    "    seed : int\n",
    "        Random seed\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    List[Experience]\n",
    "        List of experience tuples\n",
    "    \"\"\"\n",
    "    env = gym.make(env_name)\n",
    "    experiences = []\n",
    "    \n",
    "    obs, _ = env.reset(seed=seed)\n",
    "    \n",
    "    for _ in range(num_steps):\n",
    "        action = env.action_space.sample()\n",
    "        next_obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        \n",
    "        experiences.append(Experience(\n",
    "            observation=obs.copy(),\n",
    "            action=action,\n",
    "            reward=float(reward),\n",
    "            next_observation=next_obs.copy(),\n",
    "            done=done\n",
    "        ))\n",
    "        \n",
    "        if done:\n",
    "            obs, _ = env.reset()\n",
    "        else:\n",
    "            obs = next_obs\n",
    "    \n",
    "    env.close()\n",
    "    return experiences\n",
    "\n",
    "\n",
    "# Collect some experiences\n",
    "print(\"Collecting experiences from CartPole-v1...\")\n",
    "experiences = collect_experiences(\"CartPole-v1\", num_steps=500, seed=SEED)\n",
    "print(f\"Collected {len(experiences)} experience tuples\")\n",
    "print(f\"  Observation shape: {experiences[0].observation.shape}\")\n",
    "print(f\"  Action type: {type(experiences[0].action)}\")\n",
    "print(f\"  Sample reward: {experiences[0].reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Visualization Helpers\n",
    "\n",
    "Create visualization utility functions for training curves and environment rendering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell: Visualization Style Configuration\n",
    "Purpose: Set up consistent visualization style\n",
    "\"\"\"\n",
    "\n",
    "# Color palette for different approaches\n",
    "COLORS = {\n",
    "    \"baseline\": \"#2ecc71\",      # Green\n",
    "    \"qaoa\": \"#3498db\",          # Blue\n",
    "    \"superposition\": \"#9b59b6\", # Purple\n",
    "    \"gates\": \"#e74c3c\",         # Red\n",
    "    \"error_correction\": \"#f39c12\",  # Orange\n",
    "    \"integrated\": \"#1abc9c\",    # Teal\n",
    "}\n",
    "\n",
    "# Figure defaults\n",
    "FIGURE_DEFAULTS = {\n",
    "    \"figsize\": (10, 6),\n",
    "    \"dpi\": 100,\n",
    "    \"facecolor\": \"white\",\n",
    "}\n",
    "\n",
    "def setup_figure_style():\n",
    "    \"\"\"Set up matplotlib figure style.\"\"\"\n",
    "    plt.rcParams.update({\n",
    "        'figure.figsize': FIGURE_DEFAULTS['figsize'],\n",
    "        'figure.dpi': FIGURE_DEFAULTS['dpi'],\n",
    "        'figure.facecolor': FIGURE_DEFAULTS['facecolor'],\n",
    "        'axes.titlesize': 14,\n",
    "        'axes.labelsize': 12,\n",
    "        'xtick.labelsize': 10,\n",
    "        'ytick.labelsize': 10,\n",
    "        'legend.fontsize': 10,\n",
    "        'font.family': 'sans-serif',\n",
    "    })\n",
    "\n",
    "setup_figure_style()\n",
    "print(\"Visualization style configured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell: Learning Curve Plotting\n",
    "Purpose: Functions for plotting training curves\n",
    "\"\"\"\n",
    "\n",
    "def plot_learning_curve(\n",
    "    data: Dict[str, List[float]],\n",
    "    title: str = \"Learning Curve\",\n",
    "    xlabel: str = \"Steps\",\n",
    "    ylabel: str = \"Value\",\n",
    "    smooth_window: int = 10,\n",
    "    figsize: Tuple[int, int] = (10, 6),\n",
    "    save_path: Optional[str] = None\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plot learning curves with optional smoothing.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : Dict[str, List[float]]\n",
    "        Dictionary mapping method names to value lists\n",
    "    title : str\n",
    "        Plot title\n",
    "    xlabel : str\n",
    "        X-axis label\n",
    "    ylabel : str\n",
    "        Y-axis label\n",
    "    smooth_window : int\n",
    "        Window size for moving average smoothing\n",
    "    figsize : Tuple[int, int]\n",
    "        Figure size\n",
    "    save_path : Optional[str]\n",
    "        Path to save figure\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    plt.Figure\n",
    "        The matplotlib figure\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    for name, values in data.items():\n",
    "        color = COLORS.get(name, None)\n",
    "        x = np.arange(len(values))\n",
    "        \n",
    "        # Raw data (lighter)\n",
    "        ax.plot(x, values, alpha=0.3, color=color)\n",
    "        \n",
    "        # Smoothed data\n",
    "        if len(values) >= smooth_window:\n",
    "            smoothed = np.convolve(values, np.ones(smooth_window)/smooth_window, mode='valid')\n",
    "            ax.plot(np.arange(len(smoothed)) + smooth_window//2, smoothed, \n",
    "                   label=name, color=color, linewidth=2)\n",
    "        else:\n",
    "            ax.plot(x, values, label=name, color=color, linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        fig.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"Figure saved to: {save_path}\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "# Demo plot with synthetic data\n",
    "np.random.seed(SEED)\n",
    "demo_data = {\n",
    "    \"baseline\": np.cumsum(np.random.randn(100)) + np.linspace(0, 20, 100),\n",
    "    \"qaoa\": np.cumsum(np.random.randn(100)) + np.linspace(0, 25, 100),\n",
    "}\n",
    "\n",
    "fig = plot_learning_curve(\n",
    "    demo_data,\n",
    "    title=\"Demo Learning Curve\",\n",
    "    xlabel=\"Training Steps\",\n",
    "    ylabel=\"Cumulative Reward\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell: Episode Visualization\n",
    "Purpose: Visualize episode observations and rewards\n",
    "\"\"\"\n",
    "\n",
    "def plot_episode_summary(\n",
    "    experiences: List[Experience],\n",
    "    title: str = \"Episode Summary\",\n",
    "    figsize: Tuple[int, int] = (14, 8)\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plot summary of an episode's observations and rewards.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    experiences : List[Experience]\n",
    "        List of experience tuples\n",
    "    title : str\n",
    "        Plot title\n",
    "    figsize : Tuple[int, int]\n",
    "        Figure size\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    plt.Figure\n",
    "        The matplotlib figure\n",
    "    \"\"\"\n",
    "    obs = np.array([e.observation for e in experiences])\n",
    "    rewards = np.array([e.reward for e in experiences])\n",
    "    actions = np.array([e.action for e in experiences])\n",
    "    \n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    gs = GridSpec(2, 2, figure=fig)\n",
    "    \n",
    "    # Plot 1: Observations over time\n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    for i in range(obs.shape[1]):\n",
    "        ax1.plot(obs[:, i], label=f\"Obs[{i}]\", alpha=0.8)\n",
    "    ax1.set_xlabel(\"Step\")\n",
    "    ax1.set_ylabel(\"Value\")\n",
    "    ax1.set_title(\"Observations Over Time\")\n",
    "    ax1.legend(loc='upper right', ncol=obs.shape[1])\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Rewards\n",
    "    ax2 = fig.add_subplot(gs[1, 0])\n",
    "    ax2.plot(rewards, color=COLORS[\"baseline\"], linewidth=2)\n",
    "    ax2.fill_between(range(len(rewards)), rewards, alpha=0.3, color=COLORS[\"baseline\"])\n",
    "    ax2.axhline(y=np.mean(rewards), color='red', linestyle='--', label=f\"Mean: {np.mean(rewards):.2f}\")\n",
    "    ax2.set_xlabel(\"Step\")\n",
    "    ax2.set_ylabel(\"Reward\")\n",
    "    ax2.set_title(\"Rewards\")\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Action distribution\n",
    "    ax3 = fig.add_subplot(gs[1, 1])\n",
    "    if isinstance(actions[0], (int, np.integer)):\n",
    "        unique, counts = np.unique(actions, return_counts=True)\n",
    "        ax3.bar(unique, counts, color=COLORS[\"qaoa\"], alpha=0.8)\n",
    "        ax3.set_xlabel(\"Action\")\n",
    "        ax3.set_ylabel(\"Count\")\n",
    "    else:\n",
    "        ax3.hist(actions.flatten(), bins=30, color=COLORS[\"qaoa\"], alpha=0.8)\n",
    "        ax3.set_xlabel(\"Action Value\")\n",
    "        ax3.set_ylabel(\"Frequency\")\n",
    "    ax3.set_title(\"Action Distribution\")\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    fig.suptitle(title, fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "# Plot episode summary for collected experiences\n",
    "fig = plot_episode_summary(experiences[:200], title=\"CartPole Episode Summary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell: Training Loop Diagram\n",
    "Purpose: Create a visual diagram of the training loop\n",
    "\"\"\"\n",
    "\n",
    "def create_training_loop_diagram(figsize: Tuple[int, int] = (12, 8)) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Create a visual diagram of the world model training loop.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    plt.Figure\n",
    "        The matplotlib figure\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.set_xlim(0, 10)\n",
    "    ax.set_ylim(0, 8)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Define box positions and sizes\n",
    "    boxes = {\n",
    "        'Environment': (1, 6, 2, 1, '#3498db'),\n",
    "        'Agent': (1, 4, 2, 1, '#2ecc71'),\n",
    "        'Replay Buffer': (4.5, 4, 2, 1, '#9b59b6'),\n",
    "        'World Model': (7.5, 4, 2, 1, '#e74c3c'),\n",
    "        'Optimizer': (7.5, 2, 2, 1, '#f39c12'),\n",
    "    }\n",
    "    \n",
    "    # Draw boxes\n",
    "    for name, (x, y, w, h, color) in boxes.items():\n",
    "        rect = mpatches.FancyBboxPatch(\n",
    "            (x, y), w, h,\n",
    "            boxstyle=\"round,pad=0.05\",\n",
    "            facecolor=color,\n",
    "            edgecolor='black',\n",
    "            linewidth=2,\n",
    "            alpha=0.8\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(x + w/2, y + h/2, name, ha='center', va='center',\n",
    "               fontsize=11, fontweight='bold', color='white')\n",
    "    \n",
    "    # Draw arrows with labels\n",
    "    arrows = [\n",
    "        # (start, end, label, color)\n",
    "        ((2, 5), (2, 5.9), \"action\", 'black'),\n",
    "        ((2, 6.9), (2, 7.5), \"\", 'black'),\n",
    "        ((2, 7.5), (1, 7.5), \"\", 'black'),\n",
    "        ((1, 7.5), (1, 5), \"obs, reward\", 'black'),\n",
    "        ((3.1, 4.5), (4.4, 4.5), \"(s,a,r,s')\", 'black'),\n",
    "        ((6.6, 4.5), (7.4, 4.5), \"batch\", 'black'),\n",
    "        ((8.5, 3.9), (8.5, 3.1), \"loss\", 'black'),\n",
    "        ((7.4, 2.5), (3, 2.5), \"\", 'gray'),\n",
    "        ((3, 2.5), (3, 3.9), \"update\", 'gray'),\n",
    "    ]\n",
    "    \n",
    "    for start, end, label, color in arrows:\n",
    "        ax.annotate(\n",
    "            '', xy=end, xytext=start,\n",
    "            arrowprops=dict(arrowstyle='->', color=color, lw=2)\n",
    "        )\n",
    "        if label:\n",
    "            mid = ((start[0] + end[0])/2, (start[1] + end[1])/2)\n",
    "            ax.text(mid[0], mid[1] + 0.2, label, ha='center', fontsize=9)\n",
    "    \n",
    "    ax.set_title(\"World Model Training Loop\", fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "    # Add legend\n",
    "    legend_elements = [\n",
    "        mpatches.Patch(facecolor='#3498db', label='Environment'),\n",
    "        mpatches.Patch(facecolor='#2ecc71', label='Agent'),\n",
    "        mpatches.Patch(facecolor='#9b59b6', label='Replay Buffer'),\n",
    "        mpatches.Patch(facecolor='#e74c3c', label='World Model'),\n",
    "        mpatches.Patch(facecolor='#f39c12', label='Optimizer'),\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='lower right', fontsize=9)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "# Create and display the training loop diagram\n",
    "fig = create_training_loop_diagram()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Summary & Next Steps\n",
    "\n",
    "Summarize the environment setup and outline next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell: Environment Summary\n",
    "Purpose: Display summary of environment setup\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PHASE 1 COMPLETE: ENVIRONMENT SETUP SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n[1] System Configuration\")\n",
    "print(f\"    Python: {sys.version.split()[0]}\")\n",
    "print(f\"    Platform: {platform.system()} {platform.release()}\")\n",
    "\n",
    "print(\"\\n[2] Core Libraries\")\n",
    "print(f\"    PyTorch: {torch.__version__}\")\n",
    "print(f\"    NumPy: {np.__version__}\")\n",
    "print(f\"    Gymnasium: {gym.__version__}\")\n",
    "\n",
    "print(\"\\n[3] Hardware\")\n",
    "print(f\"    Device: {DEVICE}\")\n",
    "if DEVICE.type == \"cuda\":\n",
    "    props = torch.cuda.get_device_properties(0)\n",
    "    print(f\"    GPU: {props.name}\")\n",
    "    print(f\"    GPU Memory: {props.total_memory / 1024**3:.1f} GB\")\n",
    "\n",
    "print(\"\\n[4] Environments Tested\")\n",
    "print(\"    CartPole-v1: OK\")\n",
    "print(\"    Pendulum-v1: OK\")\n",
    "print(f\"    DMControl: {'Available' if DMCONTROL_AVAILABLE else 'Not Installed'}\")\n",
    "\n",
    "print(\"\\n[5] Utilities Created\")\n",
    "print(\"    MetricLogger: OK\")\n",
    "print(\"    Timer: OK\")\n",
    "print(\"    Config loader/saver: OK\")\n",
    "print(\"    Experience collector: OK\")\n",
    "print(\"    Visualization helpers: OK\")\n",
    "\n",
    "print(\"\\n[6] Reproducibility\")\n",
    "print(f\"    Seed: {SEED}\")\n",
    "print(f\"    Reproducibility verified: {reproducible}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"NEXT STEPS: Phase 2 - Classical Baseline World Model\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "In Phase 2, we will:\n",
    "  1. Implement the DreamerV3-style RSSM architecture\n",
    "  2. Create encoder, dynamics, reward, and decoder networks\n",
    "  3. Implement the training loop with Adam optimizer\n",
    "  4. Train on CartPole and Pendulum\n",
    "  5. Visualize loss curves and latent space\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell: Save Utilities to Module\n",
    "Purpose: Export utility functions to src/utils for reuse\n",
    "\"\"\"\n",
    "\n",
    "# Create utils module content\n",
    "utils_content = '''\n",
    "\"\"\"\n",
    "Utility Functions for Quantum-Enhanced World Models.\n",
    "\n",
    "Author: Saurabh Jalendra\n",
    "Institution: BITS Pilani (WILP Division)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import contextlib\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Union, Any\n",
    "from dataclasses import dataclass, field\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 42, deterministic: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Set random seeds for reproducibility across all libraries.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    seed : int\n",
    "        Random seed value\n",
    "    deterministic : bool\n",
    "        Whether to enable deterministic algorithms\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    if deterministic:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    os.environ[\\'CUBLAS_WORKSPACE_CONFIG\\'] = \\':4096:8\\'\n",
    "    os.environ[\\'PYTHONHASHSEED\\'] = str(seed)\n",
    "\n",
    "\n",
    "def get_device(prefer_gpu: bool = True) -> torch.device:\n",
    "    \"\"\"\n",
    "    Get the best available compute device.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    prefer_gpu : bool\n",
    "        Whether to prefer GPU over CPU\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    torch.device\n",
    "        The selected compute device\n",
    "    \"\"\"\n",
    "    if prefer_gpu and torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MetricLogger:\n",
    "    \"\"\"Simple metric logger for tracking training progress.\"\"\"\n",
    "    name: str\n",
    "    metrics: Dict[str, List[float]] = field(default_factory=lambda: defaultdict(list))\n",
    "    \n",
    "    def log(self, **kwargs) -> None:\n",
    "        for key, value in kwargs.items():\n",
    "            self.metrics[key].append(value)\n",
    "    \n",
    "    def get_mean(self, key: str, n: Optional[int] = None) -> float:\n",
    "        values = self.metrics[key]\n",
    "        if n is not None:\n",
    "            values = values[-n:]\n",
    "        return np.mean(values) if values else 0.0\n",
    "    \n",
    "    def to_dataframe(self) -> pd.DataFrame:\n",
    "        return pd.DataFrame(dict(self.metrics))\n",
    "    \n",
    "    def save(self, path: Union[str, Path]) -> None:\n",
    "        self.to_dataframe().to_csv(path, index=False)\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def timer(name: str = \"Operation\"):\n",
    "    \"\"\"Context manager for timing code blocks.\"\"\"\n",
    "    start = time.perf_counter()\n",
    "    timing_info = {\"name\": name}\n",
    "    try:\n",
    "        yield timing_info\n",
    "    finally:\n",
    "        elapsed = time.perf_counter() - start\n",
    "        timing_info[\"elapsed\"] = elapsed\n",
    "        print(f\"{name}: {elapsed:.4f}s\")\n",
    "\n",
    "\n",
    "def load_config(path: Union[str, Path]) -> Dict[str, Any]:\n",
    "    \"\"\"Load configuration from YAML file.\"\"\"\n",
    "    with open(path, \\'r\\') as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "\n",
    "def save_config(config: Dict[str, Any], path: Union[str, Path]) -> None:\n",
    "    \"\"\"Save configuration to YAML file.\"\"\"\n",
    "    Path(path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, \\'w\\') as f:\n",
    "        yaml.dump(config, f, default_flow_style=False)\n",
    "'''\n",
    "\n",
    "# Write to file\n",
    "utils_path = PROJECT_ROOT / \"src\" / \"utils\" / \"__init__.py\"\n",
    "utils_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(utils_path, 'w') as f:\n",
    "    f.write(utils_content)\n",
    "\n",
    "print(f\"Utilities saved to: {utils_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell: Final Verification\n",
    "Purpose: Verify all components are working\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nFinal Verification:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Test imports from our new module\n",
    "import sys\n",
    "sys.path.insert(0, str(PROJECT_ROOT / \"src\"))\n",
    "\n",
    "try:\n",
    "    from utils import set_seed, get_device, MetricLogger, timer\n",
    "    print(\"Module imports: OK\")\n",
    "except ImportError as e:\n",
    "    print(f\"Module imports: FAILED ({e})\")\n",
    "\n",
    "# Verify GPU\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Verify environments\n",
    "try:\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    obs, _ = env.reset()\n",
    "    env.close()\n",
    "    print(\"CartPole-v1: OK\")\n",
    "except Exception as e:\n",
    "    print(f\"CartPole-v1: FAILED ({e})\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(\"\\nPhase 1 Complete!\")\n",
    "print(\"Proceed to: notebooks/02_classical_baseline.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
