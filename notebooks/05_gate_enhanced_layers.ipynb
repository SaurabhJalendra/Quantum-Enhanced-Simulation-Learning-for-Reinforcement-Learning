{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 5: Gate-Enhanced Neural Layers\n",
    "\n",
    "**Quantum-Enhanced Simulation Learning for Reinforcement Learning**\n",
    "\n",
    "Author: Saurabh Jalendra  \n",
    "Institution: BITS Pilani (WILP Division)  \n",
    "Date: November 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook implements **quantum gate-inspired neural network layers** that transform\n",
    "classical neural operations using principles from quantum computing gates:\n",
    "\n",
    "### Quantum Gates Implemented\n",
    "\n",
    "1. **Hadamard Gate (H)**: Creates superposition-like feature mixing\n",
    "2. **Rotation Gates (Rx, Ry, Rz)**: Parameterized rotations in feature space\n",
    "3. **CNOT Gate**: Controlled operations creating entanglement-like correlations\n",
    "4. **Phase Gate (S, T)**: Phase shifts for feature modulation\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- **Unitary-inspired transformations**: Preserve information (approximately)\n",
    "- **Parameterized rotations**: Learnable angles for flexible transformations\n",
    "- **Entanglement-like correlations**: Feature dependencies through controlled ops\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "import math\n",
    "from typing import Dict, List, Tuple, Optional, Union, Callable\n",
    "from dataclasses import dataclass, field\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.utils import set_seed, get_device, MetricLogger, Timer, COLORS\n",
    "\n",
    "# Set seed for reproducibility\n",
    "set_seed(42)\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Quantum Gate Mathematical Foundations\n",
    "\n",
    "### Classical Quantum Gates\n",
    "\n",
    "**Hadamard Gate:**\n",
    "$$H = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 & 1 \\\\ 1 & -1 \\end{pmatrix}$$\n",
    "\n",
    "**Rotation Gates:**\n",
    "$$R_x(\\theta) = \\begin{pmatrix} \\cos(\\theta/2) & -i\\sin(\\theta/2) \\\\ -i\\sin(\\theta/2) & \\cos(\\theta/2) \\end{pmatrix}$$\n",
    "\n",
    "$$R_y(\\theta) = \\begin{pmatrix} \\cos(\\theta/2) & -\\sin(\\theta/2) \\\\ \\sin(\\theta/2) & \\cos(\\theta/2) \\end{pmatrix}$$\n",
    "\n",
    "$$R_z(\\theta) = \\begin{pmatrix} e^{-i\\theta/2} & 0 \\\\ 0 & e^{i\\theta/2} \\end{pmatrix}$$\n",
    "\n",
    "### Classical Adaptations\n",
    "\n",
    "We adapt these to real-valued neural network operations:\n",
    "- Complex exponentials become sinusoidal transformations\n",
    "- 2x2 matrices generalize to arbitrary dimensions\n",
    "- Learnable parameters replace fixed angles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Hadamard-Inspired Layer\n",
    "\n",
    "The Hadamard gate creates equal superposition. We adapt this to neural networks\n",
    "by mixing features through orthogonal-like transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HadamardLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Hadamard-inspired neural network layer.\n",
    "    \n",
    "    Creates superposition-like mixing of features using Hadamard-like\n",
    "    transformations extended to arbitrary dimensions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dim : int\n",
    "        Input/output dimension (must be power of 2 for true Hadamard)\n",
    "    learnable_scale : bool\n",
    "        Whether to learn scaling factors\n",
    "    normalize : bool\n",
    "        Whether to normalize output\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        learnable_scale: bool = True,\n",
    "        normalize: bool = True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.normalize = normalize\n",
    "        \n",
    "        # Create Hadamard-like matrix\n",
    "        H = self._create_hadamard_matrix(dim)\n",
    "        self.register_buffer('hadamard', H)\n",
    "        \n",
    "        # Learnable scaling\n",
    "        if learnable_scale:\n",
    "            self.scale = nn.Parameter(torch.ones(dim))\n",
    "        else:\n",
    "            self.register_buffer('scale', torch.ones(dim))\n",
    "        \n",
    "        # Learnable bias\n",
    "        self.bias = nn.Parameter(torch.zeros(dim))\n",
    "    \n",
    "    def _create_hadamard_matrix(self, n: int) -> Tensor:\n",
    "        \"\"\"\n",
    "        Create a Hadamard-like orthogonal matrix.\n",
    "        \n",
    "        For dimensions that are powers of 2, uses true Hadamard construction.\n",
    "        For other dimensions, uses an approximation via QR decomposition.\n",
    "        \"\"\"\n",
    "        # Check if n is power of 2\n",
    "        if n > 0 and (n & (n - 1)) == 0:\n",
    "            # True Hadamard construction via Sylvester's method\n",
    "            H = torch.tensor([[1.0]])\n",
    "            while H.shape[0] < n:\n",
    "                H = torch.cat([\n",
    "                    torch.cat([H, H], dim=1),\n",
    "                    torch.cat([H, -H], dim=1)\n",
    "                ], dim=0)\n",
    "            H = H / math.sqrt(n)\n",
    "        else:\n",
    "            # Approximate with random orthogonal matrix\n",
    "            random_matrix = torch.randn(n, n)\n",
    "            Q, _ = torch.linalg.qr(random_matrix)\n",
    "            H = Q\n",
    "        \n",
    "        return H\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Apply Hadamard-like transformation.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : Tensor\n",
    "            Input tensor of shape (batch, ..., dim)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tensor\n",
    "            Transformed tensor of same shape\n",
    "        \"\"\"\n",
    "        # Apply Hadamard transformation\n",
    "        y = F.linear(x, self.hadamard)\n",
    "        \n",
    "        # Scale and bias\n",
    "        y = y * self.scale + self.bias\n",
    "        \n",
    "        # Optional normalization\n",
    "        if self.normalize:\n",
    "            y = F.layer_norm(y, (self.dim,))\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"dim={self.dim}, normalize={self.normalize}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing HadamardLayer...\n",
      "Input shape: torch.Size([32, 64]), Output shape: torch.Size([32, 64])\n",
      "Orthogonality error (should be ~0): 0.000000\n",
      "Non-power-of-2: Input shape: torch.Size([32, 100]), Output shape: torch.Size([32, 100])\n"
     ]
    }
   ],
   "source": [
    "# Test Hadamard layer\n",
    "print(\"Testing HadamardLayer...\")\n",
    "\n",
    "# Power of 2 dimension\n",
    "hadamard_64 = HadamardLayer(64).to(device)\n",
    "x = torch.randn(32, 64, device=device)\n",
    "y = hadamard_64(x)\n",
    "print(f\"Input shape: {x.shape}, Output shape: {y.shape}\")\n",
    "\n",
    "# Verify Hadamard matrix properties\n",
    "H = hadamard_64.hadamard\n",
    "HHT = H @ H.T\n",
    "identity_error = torch.norm(HHT - torch.eye(64, device=device)).item()\n",
    "print(f\"Orthogonality error (should be ~0): {identity_error:.6f}\")\n",
    "\n",
    "# Non-power of 2 dimension\n",
    "hadamard_100 = HadamardLayer(100).to(device)\n",
    "x2 = torch.randn(32, 100, device=device)\n",
    "y2 = hadamard_100(x2)\n",
    "print(f\"Non-power-of-2: Input shape: {x2.shape}, Output shape: {y2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Rotation Gate Layers\n",
    "\n",
    "Rotation gates perform parameterized rotations in feature space.\n",
    "We implement Rx, Ry, Rz-inspired layers with learnable angles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotationLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Rotation gate-inspired neural network layer.\n",
    "    \n",
    "    Implements learnable rotations in feature space inspired by\n",
    "    quantum rotation gates (Rx, Ry, Rz).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dim : int\n",
    "        Feature dimension\n",
    "    num_rotations : int\n",
    "        Number of rotation pairs (rotations applied to pairs of features)\n",
    "    rotation_type : str\n",
    "        Type of rotation: 'xy', 'xz', 'yz', or 'all'\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        num_rotations: Optional[int] = None,\n",
    "        rotation_type: str = 'all'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.num_rotations = num_rotations or (dim // 2)\n",
    "        self.rotation_type = rotation_type\n",
    "        \n",
    "        # Learnable rotation angles\n",
    "        if rotation_type == 'all':\n",
    "            # Three angles per rotation (Rx, Ry, Rz)\n",
    "            self.angles = nn.Parameter(\n",
    "                torch.randn(self.num_rotations, 3) * 0.1\n",
    "            )\n",
    "        else:\n",
    "            # Single angle per rotation\n",
    "            self.angles = nn.Parameter(\n",
    "                torch.randn(self.num_rotations) * 0.1\n",
    "            )\n",
    "        \n",
    "        # Indices for rotation pairs\n",
    "        indices = torch.randperm(dim)[:self.num_rotations * 2]\n",
    "        self.register_buffer('idx1', indices[:self.num_rotations])\n",
    "        self.register_buffer('idx2', indices[self.num_rotations:])\n",
    "    \n",
    "    def _apply_rotation_2d(\n",
    "        self,\n",
    "        x1: Tensor,\n",
    "        x2: Tensor,\n",
    "        theta: Tensor\n",
    "    ) -> Tuple[Tensor, Tensor]:\n",
    "        \"\"\"\n",
    "        Apply 2D rotation to feature pairs.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x1, x2 : Tensor\n",
    "            Feature pairs to rotate (batch, num_rotations)\n",
    "        theta : Tensor\n",
    "            Rotation angles (num_rotations,)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[Tensor, Tensor]\n",
    "            Rotated feature pairs\n",
    "        \"\"\"\n",
    "        cos_theta = torch.cos(theta)\n",
    "        sin_theta = torch.sin(theta)\n",
    "        \n",
    "        y1 = cos_theta * x1 - sin_theta * x2\n",
    "        y2 = sin_theta * x1 + cos_theta * x2\n",
    "        \n",
    "        return y1, y2\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Apply rotation transformations.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : Tensor\n",
    "            Input tensor of shape (batch, dim)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tensor\n",
    "            Rotated tensor of same shape\n",
    "        \"\"\"\n",
    "        # Clone to avoid in-place modification\n",
    "        y = x.clone()\n",
    "        \n",
    "        # Get feature pairs\n",
    "        x1 = x[:, self.idx1]  # (batch, num_rotations)\n",
    "        x2 = x[:, self.idx2]  # (batch, num_rotations)\n",
    "        \n",
    "        if self.rotation_type == 'all':\n",
    "            # Apply Rz, Ry, Rx in sequence\n",
    "            for i in range(3):\n",
    "                x1, x2 = self._apply_rotation_2d(x1, x2, self.angles[:, i])\n",
    "        else:\n",
    "            # Single rotation\n",
    "            x1, x2 = self._apply_rotation_2d(x1, x2, self.angles)\n",
    "        \n",
    "        # Update features\n",
    "        y = y.scatter(1, self.idx1.unsqueeze(0).expand(x.shape[0], -1), x1)\n",
    "        y = y.scatter(1, self.idx2.unsqueeze(0).expand(x.shape[0], -1), x2)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"dim={self.dim}, num_rotations={self.num_rotations}, type={self.rotation_type}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing RotationLayer...\n",
      "Input shape: torch.Size([32, 64]), Output shape: torch.Size([32, 64])\n",
      "Number of rotation angles: torch.Size([32, 3])\n",
      "Average norm difference: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Test Rotation layer\n",
    "print(\"Testing RotationLayer...\")\n",
    "\n",
    "rotation_layer = RotationLayer(64, rotation_type='all').to(device)\n",
    "x = torch.randn(32, 64, device=device)\n",
    "y = rotation_layer(x)\n",
    "\n",
    "print(f\"Input shape: {x.shape}, Output shape: {y.shape}\")\n",
    "print(f\"Number of rotation angles: {rotation_layer.angles.shape}\")\n",
    "\n",
    "# Verify approximate norm preservation (rotations should preserve norms)\n",
    "x_norms = torch.norm(x, dim=1)\n",
    "y_norms = torch.norm(y, dim=1)\n",
    "norm_diff = torch.abs(x_norms - y_norms).mean().item()\n",
    "print(f\"Average norm difference: {norm_diff:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 CNOT-Inspired Layer\n",
    "\n",
    "The CNOT (Controlled-NOT) gate creates entanglement between qubits.\n",
    "We adapt this to create controlled dependencies between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNOTLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    CNOT-inspired neural network layer.\n",
    "    \n",
    "    Creates entanglement-like correlations between features through\n",
    "    controlled operations where one feature controls the transformation\n",
    "    of another.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dim : int\n",
    "        Feature dimension\n",
    "    num_controls : int\n",
    "        Number of control-target pairs\n",
    "    threshold : float\n",
    "        Activation threshold for control feature\n",
    "    learnable_threshold : bool\n",
    "        Whether threshold is learnable\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        num_controls: Optional[int] = None,\n",
    "        threshold: float = 0.0,\n",
    "        learnable_threshold: bool = True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.num_controls = num_controls or (dim // 2)\n",
    "        \n",
    "        # Learnable thresholds\n",
    "        if learnable_threshold:\n",
    "            self.threshold = nn.Parameter(\n",
    "                torch.full((self.num_controls,), threshold)\n",
    "            )\n",
    "        else:\n",
    "            self.register_buffer(\n",
    "                'threshold',\n",
    "                torch.full((self.num_controls,), threshold)\n",
    "            )\n",
    "        \n",
    "        # Learnable transformation weights for target\n",
    "        self.transform_weight = nn.Parameter(\n",
    "            torch.randn(self.num_controls) * 0.1\n",
    "        )\n",
    "        \n",
    "        # Temperature for soft thresholding\n",
    "        self.temperature = nn.Parameter(torch.tensor(1.0))\n",
    "        \n",
    "        # Control and target indices\n",
    "        indices = torch.randperm(dim)[:self.num_controls * 2]\n",
    "        self.register_buffer('control_idx', indices[:self.num_controls])\n",
    "        self.register_buffer('target_idx', indices[self.num_controls:])\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Apply CNOT-like controlled transformations.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : Tensor\n",
    "            Input tensor of shape (batch, dim)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tensor\n",
    "            Transformed tensor\n",
    "        \"\"\"\n",
    "        y = x.clone()\n",
    "        \n",
    "        # Get control and target features\n",
    "        control = x[:, self.control_idx]  # (batch, num_controls)\n",
    "        target = x[:, self.target_idx]    # (batch, num_controls)\n",
    "        \n",
    "        # Soft control activation using sigmoid\n",
    "        control_activation = torch.sigmoid(\n",
    "            (control - self.threshold) * self.temperature\n",
    "        )\n",
    "        \n",
    "        # Apply controlled transformation (like XOR in quantum, we use negation-like transform)\n",
    "        # When control is active, transform target\n",
    "        transformed_target = target + control_activation * self.transform_weight * target\n",
    "        \n",
    "        # Update targets\n",
    "        y = y.scatter(\n",
    "            1,\n",
    "            self.target_idx.unsqueeze(0).expand(x.shape[0], -1),\n",
    "            transformed_target\n",
    "        )\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def get_entanglement_strength(self) -> Tensor:\n",
    "        \"\"\"\n",
    "        Compute a measure of entanglement strength.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tensor\n",
    "            Average absolute transformation weight\n",
    "        \"\"\"\n",
    "        return torch.abs(self.transform_weight).mean()\n",
    "    \n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"dim={self.dim}, num_controls={self.num_controls}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing CNOTLayer...\n",
      "Input shape: torch.Size([32, 64]), Output shape: torch.Size([32, 64])\n",
      "Entanglement strength: 0.075891\n",
      "Target difference with high vs low control: 0.0619\n"
     ]
    }
   ],
   "source": [
    "# Test CNOT layer\n",
    "print(\"Testing CNOTLayer...\")\n",
    "\n",
    "cnot_layer = CNOTLayer(64).to(device)\n",
    "x = torch.randn(32, 64, device=device)\n",
    "y = cnot_layer(x)\n",
    "\n",
    "print(f\"Input shape: {x.shape}, Output shape: {y.shape}\")\n",
    "print(f\"Entanglement strength: {cnot_layer.get_entanglement_strength().item():.6f}\")\n",
    "\n",
    "# Show that targets change based on controls\n",
    "# When control is high, target should change more\n",
    "x_high_control = torch.randn(32, 64, device=device)\n",
    "x_high_control[:, cnot_layer.control_idx] = 5.0  # High control values\n",
    "y_high = cnot_layer(x_high_control)\n",
    "\n",
    "x_low_control = x_high_control.clone()\n",
    "x_low_control[:, cnot_layer.control_idx] = -5.0  # Low control values\n",
    "y_low = cnot_layer(x_low_control)\n",
    "\n",
    "# Target difference should be larger than control difference\n",
    "target_diff = (y_high[:, cnot_layer.target_idx] - y_low[:, cnot_layer.target_idx]).abs().mean()\n",
    "print(f\"Target difference with high vs low control: {target_diff.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Phase Gate Layer\n",
    "\n",
    "Phase gates apply phase shifts to quantum states. We adapt this\n",
    "to apply learnable modulations to features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhaseLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Phase gate-inspired neural network layer.\n",
    "    \n",
    "    Applies learnable phase-like modulations to features using\n",
    "    sinusoidal transformations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dim : int\n",
    "        Feature dimension\n",
    "    phase_type : str\n",
    "        Type of phase gate: 'S' (pi/2), 'T' (pi/4), or 'learnable'\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        phase_type: str = 'learnable'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.phase_type = phase_type\n",
    "        \n",
    "        if phase_type == 'S':\n",
    "            # S gate: pi/2 phase\n",
    "            self.register_buffer('phases', torch.full((dim,), math.pi / 2))\n",
    "        elif phase_type == 'T':\n",
    "            # T gate: pi/4 phase\n",
    "            self.register_buffer('phases', torch.full((dim,), math.pi / 4))\n",
    "        else:\n",
    "            # Learnable phases\n",
    "            self.phases = nn.Parameter(torch.randn(dim) * 0.1)\n",
    "        \n",
    "        # Learnable amplitude modulation\n",
    "        self.amplitude = nn.Parameter(torch.ones(dim))\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Apply phase modulation.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : Tensor\n",
    "            Input tensor of shape (batch, dim)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tensor\n",
    "            Phase-modulated tensor\n",
    "        \"\"\"\n",
    "        # Apply phase shift through sinusoidal modulation\n",
    "        # y = amplitude * (x * cos(phase) + |x| * sin(phase))\n",
    "        cos_phase = torch.cos(self.phases)\n",
    "        sin_phase = torch.sin(self.phases)\n",
    "        \n",
    "        y = self.amplitude * (x * cos_phase + torch.abs(x) * sin_phase)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"dim={self.dim}, type={self.phase_type}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing PhaseLayer...\n",
      "Phase type 'S': Input shape torch.Size([32, 64]), Output shape torch.Size([32, 64])\n",
      "Phase type 'T': Input shape torch.Size([32, 64]), Output shape torch.Size([32, 64])\n",
      "Phase type 'learnable': Input shape torch.Size([32, 64]), Output shape torch.Size([32, 64])\n"
     ]
    }
   ],
   "source": [
    "# Test Phase layer\n",
    "print(\"Testing PhaseLayer...\")\n",
    "\n",
    "for phase_type in ['S', 'T', 'learnable']:\n",
    "    phase_layer = PhaseLayer(64, phase_type=phase_type).to(device)\n",
    "    x = torch.randn(32, 64, device=device)\n",
    "    y = phase_layer(x)\n",
    "    print(f\"Phase type '{phase_type}': Input shape {x.shape}, Output shape {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 Composite Quantum Gate Block\n",
    "\n",
    "Combine multiple gate layers into a single quantum-inspired block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumGateBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Composite quantum gate-inspired neural network block.\n",
    "    \n",
    "    Combines Hadamard, Rotation, CNOT, and Phase layers in a\n",
    "    configurable sequence similar to quantum circuits.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dim : int\n",
    "        Feature dimension\n",
    "    num_layers : int\n",
    "        Number of gate layers in sequence\n",
    "    use_hadamard : bool\n",
    "        Include Hadamard layers\n",
    "    use_rotation : bool\n",
    "        Include Rotation layers\n",
    "    use_cnot : bool\n",
    "        Include CNOT layers\n",
    "    use_phase : bool\n",
    "        Include Phase layers\n",
    "    residual : bool\n",
    "        Use residual connections\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        num_layers: int = 2,\n",
    "        use_hadamard: bool = True,\n",
    "        use_rotation: bool = True,\n",
    "        use_cnot: bool = True,\n",
    "        use_phase: bool = True,\n",
    "        residual: bool = True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.residual = residual\n",
    "        \n",
    "        layers = []\n",
    "        for i in range(num_layers):\n",
    "            layer_gates = []\n",
    "            \n",
    "            if use_hadamard:\n",
    "                layer_gates.append(HadamardLayer(dim, normalize=True))\n",
    "            \n",
    "            if use_rotation:\n",
    "                layer_gates.append(RotationLayer(dim, rotation_type='all'))\n",
    "            \n",
    "            if use_cnot:\n",
    "                layer_gates.append(CNOTLayer(dim))\n",
    "            \n",
    "            if use_phase:\n",
    "                layer_gates.append(PhaseLayer(dim, phase_type='learnable'))\n",
    "            \n",
    "            layers.append(nn.Sequential(*layer_gates))\n",
    "        \n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        \n",
    "        # Layer norm for residual\n",
    "        if residual:\n",
    "            self.layer_norms = nn.ModuleList([\n",
    "                nn.LayerNorm(dim) for _ in range(num_layers)\n",
    "            ])\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Apply quantum gate block.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : Tensor\n",
    "            Input tensor of shape (batch, dim)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tensor\n",
    "            Transformed tensor\n",
    "        \"\"\"\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if self.residual:\n",
    "                x = x + self.layer_norms[i](layer(x))\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"dim={self.dim}, num_layers={len(self.layers)}, residual={self.residual}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing QuantumGateBlock...\n",
      "Input shape: torch.Size([32, 64]), Output shape: torch.Size([32, 64])\n",
      "Number of parameters: 1635\n",
      "\n",
      "Block structure:\n",
      "QuantumGateBlock(\n",
      "  dim=64, num_layers=3, residual=True\n",
      "  (layers): ModuleList(\n",
      "    (0-2): 3 x Sequential(\n",
      "      (0): HadamardLayer(dim=64, normalize=True)\n",
      "      (1): RotationLayer(dim=64, num_rotations=32, type=all)\n",
      "      (2): CNOTLayer(dim=64, num_controls=32)\n",
      "      (3): PhaseLayer(dim=64, type=learnable)\n",
      "    )\n",
      "  )\n",
      "  (layer_norms): ModuleList(\n",
      "    (0-2): 3 x LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Test Quantum Gate Block\n",
    "print(\"Testing QuantumGateBlock...\")\n",
    "\n",
    "gate_block = QuantumGateBlock(\n",
    "    dim=64,\n",
    "    num_layers=3,\n",
    "    use_hadamard=True,\n",
    "    use_rotation=True,\n",
    "    use_cnot=True,\n",
    "    use_phase=True,\n",
    "    residual=True\n",
    ").to(device)\n",
    "\n",
    "x = torch.randn(32, 64, device=device)\n",
    "y = gate_block(x)\n",
    "\n",
    "print(f\"Input shape: {x.shape}, Output shape: {y.shape}\")\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in gate_block.parameters())}\")\n",
    "print(f\"\\nBlock structure:\")\n",
    "print(gate_block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.8 Gate-Enhanced World Model Components\n",
    "\n",
    "Now we integrate quantum gate layers into the world model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GateEnhancedEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder with quantum gate-enhanced layers.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    obs_dim : int\n",
    "        Observation dimension\n",
    "    hidden_dim : int\n",
    "        Hidden layer dimension\n",
    "    embed_dim : int\n",
    "        Output embedding dimension\n",
    "    num_gate_layers : int\n",
    "        Number of quantum gate blocks\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        obs_dim: int,\n",
    "        hidden_dim: int = 512,\n",
    "        embed_dim: int = 64,\n",
    "        num_gate_layers: int = 2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Input projection\n",
    "        self.input_proj = nn.Linear(obs_dim, hidden_dim)\n",
    "        \n",
    "        # Quantum gate block\n",
    "        self.gate_block = QuantumGateBlock(\n",
    "            dim=hidden_dim,\n",
    "            num_layers=num_gate_layers,\n",
    "            residual=True\n",
    "        )\n",
    "        \n",
    "        # Output projection\n",
    "        self.output_proj = nn.Sequential(\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Linear(hidden_dim, embed_dim),\n",
    "            nn.ELU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, obs: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Encode observations.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        obs : Tensor\n",
    "            Observations of shape (batch, obs_dim)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tensor\n",
    "            Embeddings of shape (batch, embed_dim)\n",
    "        \"\"\"\n",
    "        x = F.elu(self.input_proj(obs))\n",
    "        x = self.gate_block(x)\n",
    "        return self.output_proj(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GateEnhancedDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoder with quantum gate-enhanced layers.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    state_dim : int\n",
    "        State dimension (deterministic + stochastic)\n",
    "    hidden_dim : int\n",
    "        Hidden layer dimension\n",
    "    obs_dim : int\n",
    "        Output observation dimension\n",
    "    num_gate_layers : int\n",
    "        Number of quantum gate blocks\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        state_dim: int,\n",
    "        hidden_dim: int = 512,\n",
    "        obs_dim: int = 4,\n",
    "        num_gate_layers: int = 2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Input projection\n",
    "        self.input_proj = nn.Linear(state_dim, hidden_dim)\n",
    "        \n",
    "        # Quantum gate block\n",
    "        self.gate_block = QuantumGateBlock(\n",
    "            dim=hidden_dim,\n",
    "            num_layers=num_gate_layers,\n",
    "            residual=True\n",
    "        )\n",
    "        \n",
    "        # Output layers (mean and log_std)\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ELU()\n",
    "        )\n",
    "        self.mean = nn.Linear(hidden_dim // 2, obs_dim)\n",
    "        self.log_std = nn.Linear(hidden_dim // 2, obs_dim)\n",
    "    \n",
    "    def forward(self, state: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        \"\"\"\n",
    "        Decode state to observation distribution.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        state : Tensor\n",
    "            State of shape (batch, state_dim)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[Tensor, Tensor]\n",
    "            Mean and log_std of predicted observation distribution\n",
    "        \"\"\"\n",
    "        x = F.elu(self.input_proj(state))\n",
    "        x = self.gate_block(x)\n",
    "        x = self.output_layer(x)\n",
    "        \n",
    "        mean = self.mean(x)\n",
    "        log_std = self.log_std(x).clamp(-10, 2)\n",
    "        \n",
    "        return mean, log_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GateEnhancedRSSM(nn.Module):\n",
    "    \"\"\"\n",
    "    RSSM with quantum gate-enhanced transition model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    embed_dim : int\n",
    "        Embedding dimension from encoder\n",
    "    action_dim : int\n",
    "        Action dimension\n",
    "    deter_dim : int\n",
    "        Deterministic state dimension\n",
    "    stoch_dim : int\n",
    "        Stochastic state dimension\n",
    "    hidden_dim : int\n",
    "        Hidden layer dimension\n",
    "    num_gate_layers : int\n",
    "        Number of quantum gate layers in transition\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim: int = 64,\n",
    "        action_dim: int = 1,\n",
    "        deter_dim: int = 512,\n",
    "        stoch_dim: int = 64,\n",
    "        hidden_dim: int = 512,\n",
    "        num_gate_layers: int = 2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.deter_dim = deter_dim\n",
    "        self.stoch_dim = stoch_dim\n",
    "        \n",
    "        # GRU cell for deterministic state\n",
    "        self.gru = nn.GRUCell(stoch_dim + action_dim, deter_dim)\n",
    "        \n",
    "        # Gate-enhanced prior (imagination)\n",
    "        self.prior_gate = QuantumGateBlock(\n",
    "            dim=hidden_dim,\n",
    "            num_layers=num_gate_layers,\n",
    "            residual=True\n",
    "        )\n",
    "        self.prior_input = nn.Linear(deter_dim, hidden_dim)\n",
    "        self.prior_output = nn.Linear(hidden_dim, stoch_dim * 2)\n",
    "        \n",
    "        # Gate-enhanced posterior (with observation)\n",
    "        self.posterior_gate = QuantumGateBlock(\n",
    "            dim=hidden_dim,\n",
    "            num_layers=num_gate_layers,\n",
    "            residual=True\n",
    "        )\n",
    "        self.posterior_input = nn.Linear(deter_dim + embed_dim, hidden_dim)\n",
    "        self.posterior_output = nn.Linear(hidden_dim, stoch_dim * 2)\n",
    "    \n",
    "    def initial_state(self, batch_size: int, device: torch.device) -> Dict[str, Tensor]:\n",
    "        \"\"\"Get initial state.\"\"\"\n",
    "        return {\n",
    "            'deter': torch.zeros(batch_size, self.deter_dim, device=device),\n",
    "            'stoch': torch.zeros(batch_size, self.stoch_dim, device=device)\n",
    "        }\n",
    "    \n",
    "    def get_full_state(self, state: Dict[str, Tensor]) -> Tensor:\n",
    "        \"\"\"Concatenate deterministic and stochastic states.\"\"\"\n",
    "        return torch.cat([state['deter'], state['stoch']], dim=-1)\n",
    "    \n",
    "    def prior(self, deter: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        \"\"\"\n",
    "        Compute prior distribution (for imagination).\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        deter : Tensor\n",
    "            Deterministic state\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[Tensor, Tensor]\n",
    "            Mean and std of prior distribution\n",
    "        \"\"\"\n",
    "        x = F.elu(self.prior_input(deter))\n",
    "        x = self.prior_gate(x)\n",
    "        stats = self.prior_output(x)\n",
    "        mean, log_std = torch.chunk(stats, 2, dim=-1)\n",
    "        std = F.softplus(log_std) + 0.1\n",
    "        return mean, std\n",
    "    \n",
    "    def posterior(self, deter: Tensor, embed: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        \"\"\"\n",
    "        Compute posterior distribution (with observation).\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        deter : Tensor\n",
    "            Deterministic state\n",
    "        embed : Tensor\n",
    "            Observation embedding\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[Tensor, Tensor]\n",
    "            Mean and std of posterior distribution\n",
    "        \"\"\"\n",
    "        x = torch.cat([deter, embed], dim=-1)\n",
    "        x = F.elu(self.posterior_input(x))\n",
    "        x = self.posterior_gate(x)\n",
    "        stats = self.posterior_output(x)\n",
    "        mean, log_std = torch.chunk(stats, 2, dim=-1)\n",
    "        std = F.softplus(log_std) + 0.1\n",
    "        return mean, std\n",
    "    \n",
    "    def step(\n",
    "        self,\n",
    "        prev_state: Dict[str, Tensor],\n",
    "        action: Tensor,\n",
    "        embed: Optional[Tensor] = None\n",
    "    ) -> Tuple[Dict[str, Tensor], Dict[str, Tensor]]:\n",
    "        \"\"\"\n",
    "        Single step of RSSM.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        prev_state : Dict[str, Tensor]\n",
    "            Previous state with 'deter' and 'stoch'\n",
    "        action : Tensor\n",
    "            Action taken\n",
    "        embed : Optional[Tensor]\n",
    "            Observation embedding (None for imagination)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[Dict[str, Tensor], Dict[str, Tensor]]\n",
    "            New state and distribution stats\n",
    "        \"\"\"\n",
    "        # Update deterministic state\n",
    "        gru_input = torch.cat([prev_state['stoch'], action], dim=-1)\n",
    "        deter = self.gru(gru_input, prev_state['deter'])\n",
    "        \n",
    "        # Get prior\n",
    "        prior_mean, prior_std = self.prior(deter)\n",
    "        \n",
    "        # Get posterior if embed available, otherwise use prior\n",
    "        if embed is not None:\n",
    "            post_mean, post_std = self.posterior(deter, embed)\n",
    "            # Sample from posterior\n",
    "            stoch = post_mean + post_std * torch.randn_like(post_std)\n",
    "        else:\n",
    "            post_mean, post_std = prior_mean, prior_std\n",
    "            # Sample from prior\n",
    "            stoch = prior_mean + prior_std * torch.randn_like(prior_std)\n",
    "        \n",
    "        new_state = {'deter': deter, 'stoch': stoch}\n",
    "        stats = {\n",
    "            'prior_mean': prior_mean,\n",
    "            'prior_std': prior_std,\n",
    "            'post_mean': post_mean,\n",
    "            'post_std': post_std\n",
    "        }\n",
    "        \n",
    "        return new_state, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GateEnhancedWorldModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Complete world model with quantum gate-enhanced components.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    obs_dim : int\n",
    "        Observation dimension\n",
    "    action_dim : int\n",
    "        Action dimension\n",
    "    config : Optional[Dict]\n",
    "        Configuration dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        obs_dim: int,\n",
    "        action_dim: int,\n",
    "        config: Optional[Dict] = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        config = config or {}\n",
    "        \n",
    "        # Dimensions\n",
    "        hidden_dim = config.get('hidden_dim', 512)\n",
    "        embed_dim = config.get('embed_dim', 64)\n",
    "        deter_dim = config.get('deter_dim', 512)\n",
    "        stoch_dim = config.get('stoch_dim', 64)\n",
    "        num_gate_layers = config.get('num_gate_layers', 2)\n",
    "        \n",
    "        self.obs_dim = obs_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.state_dim = deter_dim + stoch_dim\n",
    "        \n",
    "        # Components\n",
    "        self.encoder = GateEnhancedEncoder(\n",
    "            obs_dim, hidden_dim, embed_dim, num_gate_layers\n",
    "        )\n",
    "        self.decoder = GateEnhancedDecoder(\n",
    "            self.state_dim, hidden_dim, obs_dim, num_gate_layers\n",
    "        )\n",
    "        self.rssm = GateEnhancedRSSM(\n",
    "            embed_dim, action_dim, deter_dim, stoch_dim, hidden_dim, num_gate_layers\n",
    "        )\n",
    "        \n",
    "        # Reward and continue predictors\n",
    "        self.reward_pred = nn.Sequential(\n",
    "            nn.Linear(self.state_dim, hidden_dim // 2),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_dim // 2, 1)\n",
    "        )\n",
    "        self.continue_pred = nn.Sequential(\n",
    "            nn.Linear(self.state_dim, hidden_dim // 2),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_dim // 2, 1)\n",
    "        )\n",
    "    \n",
    "    def initial_state(self, batch_size: int, device: torch.device) -> Dict[str, Tensor]:\n",
    "        \"\"\"Get initial RSSM state.\"\"\"\n",
    "        return self.rssm.initial_state(batch_size, device)\n",
    "    \n",
    "    def encode(self, obs: Tensor) -> Tensor:\n",
    "        \"\"\"Encode observation.\"\"\"\n",
    "        return self.encoder(obs)\n",
    "    \n",
    "    def decode(self, state: Dict[str, Tensor]) -> Tuple[Tensor, Tensor]:\n",
    "        \"\"\"Decode state to observation distribution.\"\"\"\n",
    "        full_state = self.rssm.get_full_state(state)\n",
    "        return self.decoder(full_state)\n",
    "    \n",
    "    def predict_reward(self, state: Dict[str, Tensor]) -> Tensor:\n",
    "        \"\"\"Predict reward from state.\"\"\"\n",
    "        full_state = self.rssm.get_full_state(state)\n",
    "        return self.reward_pred(full_state).squeeze(-1)\n",
    "    \n",
    "    def predict_continue(self, state: Dict[str, Tensor]) -> Tensor:\n",
    "        \"\"\"Predict continue probability from state.\"\"\"\n",
    "        full_state = self.rssm.get_full_state(state)\n",
    "        return torch.sigmoid(self.continue_pred(full_state)).squeeze(-1)\n",
    "    \n",
    "    def step(\n",
    "        self,\n",
    "        prev_state: Dict[str, Tensor],\n",
    "        action: Tensor,\n",
    "        obs: Optional[Tensor] = None\n",
    "    ) -> Tuple[Dict[str, Tensor], Dict[str, Tensor]]:\n",
    "        \"\"\"\n",
    "        Single step of world model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        prev_state : Dict[str, Tensor]\n",
    "            Previous RSSM state\n",
    "        action : Tensor\n",
    "            Action taken\n",
    "        obs : Optional[Tensor]\n",
    "            Observation (None for imagination)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[Dict[str, Tensor], Dict[str, Tensor]]\n",
    "            New state and distribution stats\n",
    "        \"\"\"\n",
    "        embed = self.encode(obs) if obs is not None else None\n",
    "        return self.rssm.step(prev_state, action, embed)\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        obs_seq: Tensor,\n",
    "        action_seq: Tensor\n",
    "    ) -> Dict[str, Tensor]:\n",
    "        \"\"\"\n",
    "        Process a sequence through the world model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        obs_seq : Tensor\n",
    "            Observations (batch, seq_len, obs_dim)\n",
    "        action_seq : Tensor\n",
    "            Actions (batch, seq_len, action_dim)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, Tensor]\n",
    "            Dictionary with states, predictions, and distribution stats\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = obs_seq.shape[:2]\n",
    "        device = obs_seq.device\n",
    "        \n",
    "        # Initialize\n",
    "        state = self.initial_state(batch_size, device)\n",
    "        \n",
    "        # Collect outputs\n",
    "        states = []\n",
    "        prior_means, prior_stds = [], []\n",
    "        post_means, post_stds = [], []\n",
    "        \n",
    "        for t in range(seq_len):\n",
    "            state, stats = self.step(state, action_seq[:, t], obs_seq[:, t])\n",
    "            \n",
    "            states.append(self.rssm.get_full_state(state))\n",
    "            prior_means.append(stats['prior_mean'])\n",
    "            prior_stds.append(stats['prior_std'])\n",
    "            post_means.append(stats['post_mean'])\n",
    "            post_stds.append(stats['post_std'])\n",
    "        \n",
    "        # Stack\n",
    "        states = torch.stack(states, dim=1)\n",
    "        \n",
    "        # Decode all states\n",
    "        flat_states = states.reshape(-1, states.shape[-1])\n",
    "        obs_mean, obs_log_std = self.decoder(flat_states)\n",
    "        obs_mean = obs_mean.reshape(batch_size, seq_len, -1)\n",
    "        obs_log_std = obs_log_std.reshape(batch_size, seq_len, -1)\n",
    "        \n",
    "        # Predict rewards\n",
    "        reward_pred = self.reward_pred(flat_states).reshape(batch_size, seq_len)\n",
    "        \n",
    "        return {\n",
    "            'states': states,\n",
    "            'obs_mean': obs_mean,\n",
    "            'obs_log_std': obs_log_std,\n",
    "            'reward_pred': reward_pred,\n",
    "            'prior_mean': torch.stack(prior_means, dim=1),\n",
    "            'prior_std': torch.stack(prior_stds, dim=1),\n",
    "            'post_mean': torch.stack(post_means, dim=1),\n",
    "            'post_std': torch.stack(post_stds, dim=1)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing GateEnhancedWorldModel...\n",
      "States shape: torch.Size([16, 20, 160])\n",
      "Obs mean shape: torch.Size([16, 20, 4])\n",
      "Reward pred shape: torch.Size([16, 20])\n",
      "\n",
      "Total parameters: 330,706\n"
     ]
    }
   ],
   "source": [
    "# Test Gate-Enhanced World Model\n",
    "print(\"Testing GateEnhancedWorldModel...\")\n",
    "\n",
    "model = GateEnhancedWorldModel(\n",
    "    obs_dim=4,\n",
    "    action_dim=1,\n",
    "    config={'num_gate_layers': 2}\n",
    ").to(device)\n",
    "\n",
    "# Test forward pass\n",
    "batch_size, seq_len=20, 20\n",
    "obs_seq = torch.randn(batch_size, seq_len, 4, device=device)\n",
    "action_seq = torch.randn(batch_size, seq_len, 1, device=device)\n",
    "\n",
    "outputs = model(obs_seq, action_seq)\n",
    "\n",
    "print(f\"States shape: {outputs['states'].shape}\")\n",
    "print(f\"Obs mean shape: {outputs['obs_mean'].shape}\")\n",
    "print(f\"Reward pred shape: {outputs['reward_pred'].shape}\")\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.9 Gate-Enhanced Training\n",
    "\n",
    "Training loop for the gate-enhanced world model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GateEnhancedTrainer:\n",
    "    \"\"\"\n",
    "    Trainer for gate-enhanced world model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : GateEnhancedWorldModel\n",
    "        The world model to train\n",
    "    learning_rate : float\n",
    "        Learning rate\n",
    "    kl_weight : float\n",
    "        Weight for KL divergence loss\n",
    "    free_nats : float\n",
    "        Free nats for KL loss\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model: GateEnhancedWorldModel,\n",
    "        learning_rate: float = 1e-4,\n",
    "        kl_weight: float = 1.0,\n",
    "        free_nats: float = 3.0\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.kl_weight = kl_weight\n",
    "        self.free_nats = free_nats\n",
    "        \n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=learning_rate,\n",
    "            weight_decay=1e-5\n",
    "        )\n",
    "        \n",
    "        self.logger = MetricLogger(name='gate_enhanced')\n",
    "    \n",
    "    def compute_loss(\n",
    "        self,\n",
    "        obs_seq: Tensor,\n",
    "        action_seq: Tensor,\n",
    "        reward_seq: Tensor\n",
    "    ) -> Tuple[Tensor, Dict[str, float]]:\n",
    "        \"\"\"\n",
    "        Compute training loss.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        obs_seq : Tensor\n",
    "            Observations (batch, seq_len, obs_dim)\n",
    "        action_seq : Tensor\n",
    "            Actions (batch, seq_len, action_dim)\n",
    "        reward_seq : Tensor\n",
    "            Rewards (batch, seq_len)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[Tensor, Dict[str, float]]\n",
    "            Total loss and individual loss components\n",
    "        \"\"\"\n",
    "        outputs = self.model(obs_seq, action_seq)\n",
    "        \n",
    "        # Reconstruction loss\n",
    "        obs_dist = torch.distributions.Normal(\n",
    "            outputs['obs_mean'],\n",
    "            torch.exp(outputs['obs_log_std'])\n",
    "        )\n",
    "        recon_loss = -obs_dist.log_prob(obs_seq).mean()\n",
    "        \n",
    "        # KL divergence loss with free nats\n",
    "        prior_dist = torch.distributions.Normal(\n",
    "            outputs['prior_mean'],\n",
    "            outputs['prior_std']\n",
    "        )\n",
    "        post_dist = torch.distributions.Normal(\n",
    "            outputs['post_mean'],\n",
    "            outputs['post_std']\n",
    "        )\n",
    "        kl_div = torch.distributions.kl_divergence(post_dist, prior_dist)\n",
    "        kl_loss = torch.maximum(\n",
    "            kl_div.mean(),\n",
    "            torch.tensor(self.free_nats, device=kl_div.device)\n",
    "        )\n",
    "        \n",
    "        # Reward loss\n",
    "        reward_loss = F.mse_loss(outputs['reward_pred'], reward_seq)\n",
    "        \n",
    "        # Total loss\n",
    "        total_loss = recon_loss + self.kl_weight * kl_loss + reward_loss\n",
    "        \n",
    "        metrics = {\n",
    "            'recon_loss': recon_loss.item(),\n",
    "            'kl_loss': kl_loss.item(),\n",
    "            'reward_loss': reward_loss.item(),\n",
    "            'total_loss': total_loss.item()\n",
    "        }\n",
    "        \n",
    "        return total_loss, metrics\n",
    "    \n",
    "    def train_step(\n",
    "        self,\n",
    "        obs_seq: Tensor,\n",
    "        action_seq: Tensor,\n",
    "        reward_seq: Tensor\n",
    "    ) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Single training step.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, float]\n",
    "            Loss metrics\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        loss, metrics = self.compute_loss(obs_seq, action_seq, reward_seq)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), 100.0)\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # Log metrics\n",
    "        for key, value in metrics.items():\n",
    "            self.logger.log(**{key: value})\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def evaluate(\n",
    "        self,\n",
    "        obs_seq: Tensor,\n",
    "        action_seq: Tensor,\n",
    "        reward_seq: Tensor\n",
    "    ) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Evaluate model.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, float]\n",
    "            Loss metrics\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            _, metrics = self.compute_loss(obs_seq, action_seq, reward_seq)\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing GateEnhancedTrainer...\n",
      "Training metrics:\n",
      "  recon_loss: 1.5177\n",
      "  kl_loss: 3.3462\n",
      "  reward_loss: 1.1470\n",
      "  total_loss: 6.0110\n"
     ]
    }
   ],
   "source": [
    "# Test Gate-Enhanced Trainer\n",
    "print(\"Testing GateEnhancedTrainer...\")\n",
    "\n",
    "model = GateEnhancedWorldModel(obs_dim=4, action_dim=1).to(device)\n",
    "trainer = GateEnhancedTrainer(model)\n",
    "\n",
    "# Generate synthetic data\n",
    "obs_seq = torch.randn(16, 20, 4, device=device)\n",
    "action_seq = torch.randn(16, 20, 1, device=device)\n",
    "reward_seq = torch.randn(16, 20, device=device)\n",
    "\n",
    "# Run training step\n",
    "metrics = trainer.train_step(obs_seq, action_seq, reward_seq)\n",
    "print(f\"Training metrics:\")\n",
    "for key, value in metrics.items():\n",
    "    print(f\"  {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.10 Comparison: Gate-Enhanced vs Standard\n",
    "\n",
    "Compare the gate-enhanced world model against the standard baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from collections import deque\n",
    "\n",
    "def collect_episodes(\n",
    "    env_name: str,\n",
    "    num_episodes: int = 10,\n",
    "    max_steps: int = 500\n",
    ") -> List[Dict[str, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Collect episodes from environment.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    env_name : str\n",
    "        Environment name\n",
    "    num_episodes : int\n",
    "        Number of episodes to collect\n",
    "    max_steps : int\n",
    "        Maximum steps per episode\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    List[Dict]\n",
    "        List of episode dictionaries\n",
    "    \"\"\"\n",
    "    env = gym.make(env_name)\n",
    "    episodes = []\n",
    "    \n",
    "    for _ in range(num_episodes):\n",
    "        obs_list, action_list, reward_list = [], [], []\n",
    "        \n",
    "        obs, _ = env.reset()\n",
    "        obs_list.append(obs)\n",
    "        \n",
    "        for _ in range(max_steps):\n",
    "            action = env.action_space.sample()\n",
    "            next_obs, reward, terminated, truncated, _ = env.step(action)\n",
    "            \n",
    "            # Ensure action is always a list/array for consistent shape\n",
    "            if np.isscalar(action):\n",
    "                action_list.append([float(action)])\n",
    "            else:\n",
    "                action_list.append(action)\n",
    "            reward_list.append(reward)\n",
    "            obs_list.append(next_obs)\n",
    "            \n",
    "            if terminated or truncated:\n",
    "                break\n",
    "            obs = next_obs\n",
    "        \n",
    "        # Remove last obs (not paired with action)\n",
    "        obs_list = obs_list[:-1]\n",
    "        \n",
    "        # Accept shorter episodes too (minimum 5 steps instead of 10)\n",
    "        if len(obs_list) >= 5:\n",
    "            episodes.append({\n",
    "                'obs': np.array(obs_list, dtype=np.float32),\n",
    "                'actions': np.array(action_list, dtype=np.float32),\n",
    "                'rewards': np.array(reward_list, dtype=np.float32)\n",
    "            })\n",
    "    \n",
    "    env.close()\n",
    "    return episodes\n",
    "\n",
    "\n",
    "def create_batches(\n",
    "    episodes: List[Dict],\n",
    "    batch_size: int = 32,\n",
    "    seq_len: int = 20,\n",
    "    device: torch.device = device\n",
    ") -> List[Tuple[Tensor, Tensor, Tensor]]:\n",
    "    \"\"\"\n",
    "    Create training batches from episodes.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    episodes : List[Dict]\n",
    "        List of episode dictionaries\n",
    "    batch_size : int\n",
    "        Batch size\n",
    "    seq_len : int\n",
    "        Sequence length\n",
    "    device : torch.device\n",
    "        Device to put tensors on\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    List[Tuple[Tensor, Tensor, Tensor]]\n",
    "        List of (obs, actions, rewards) batches\n",
    "    \"\"\"\n",
    "    # Collect all valid sequences\n",
    "    sequences = []\n",
    "    for ep in episodes:\n",
    "        ep_len = len(ep['obs'])\n",
    "        # If episode is shorter than seq_len, use what we have (pad or skip)\n",
    "        if ep_len >= seq_len:\n",
    "            for start in range(0, ep_len - seq_len + 1, max(1, seq_len // 2)):\n",
    "                sequences.append({\n",
    "                    'obs': ep['obs'][start:start+seq_len],\n",
    "                    'actions': ep['actions'][start:start+seq_len],\n",
    "                    'rewards': ep['rewards'][start:start+seq_len]\n",
    "                })\n",
    "        elif ep_len >= seq_len // 2:\n",
    "            # For shorter episodes, pad to seq_len\n",
    "            pad_len = seq_len - ep_len\n",
    "            obs_padded = np.pad(ep['obs'], ((0, pad_len), (0, 0)), mode='edge')\n",
    "            actions_padded = np.pad(ep['actions'], ((0, pad_len), (0, 0)), mode='edge')\n",
    "            rewards_padded = np.pad(ep['rewards'], (0, pad_len), mode='edge')\n",
    "            sequences.append({\n",
    "                'obs': obs_padded[:seq_len],\n",
    "                'actions': actions_padded[:seq_len],\n",
    "                'rewards': rewards_padded[:seq_len]\n",
    "            })\n",
    "    \n",
    "    if len(sequences) == 0:\n",
    "        print(f\"WARNING: No valid sequences found! Episode lengths may be too short.\")\n",
    "        return []\n",
    "    \n",
    "    # Shuffle and batch\n",
    "    np.random.shuffle(sequences)\n",
    "    batches = []\n",
    "    \n",
    "    # Handle case where we have fewer sequences than batch_size\n",
    "    if len(sequences) < batch_size:\n",
    "        batch_size = max(1, len(sequences))\n",
    "    \n",
    "    for i in range(0, len(sequences) - batch_size + 1, batch_size):\n",
    "        batch_seqs = sequences[i:i+batch_size]\n",
    "        \n",
    "        obs = torch.tensor(\n",
    "            np.stack([s['obs'] for s in batch_seqs]),\n",
    "            dtype=torch.float32, device=device\n",
    "        )\n",
    "        actions = torch.tensor(\n",
    "            np.stack([s['actions'] for s in batch_seqs]),\n",
    "            dtype=torch.float32, device=device\n",
    "        )\n",
    "        rewards = torch.tensor(\n",
    "            np.stack([s['rewards'] for s in batch_seqs]),\n",
    "            dtype=torch.float32, device=device\n",
    "        )\n",
    "        \n",
    "        batches.append((obs, actions, rewards))\n",
    "    \n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard World Model for comparison (from Phase 2)\n",
    "class StandardWorldModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Standard world model without quantum gate enhancements.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, obs_dim: int, action_dim: int, config: Optional[Dict] = None):\n",
    "        super().__init__()\n",
    "        config = config or {}\n",
    "        \n",
    "        hidden_dim = config.get('hidden_dim', 512)\n",
    "        embed_dim = config.get('embed_dim', 64)\n",
    "        deter_dim = config.get('deter_dim', 512)\n",
    "        stoch_dim = config.get('stoch_dim', 64)\n",
    "        \n",
    "        self.obs_dim = obs_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.state_dim = deter_dim + stoch_dim\n",
    "        self.deter_dim = deter_dim\n",
    "        self.stoch_dim = stoch_dim\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(obs_dim, hidden_dim),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_dim, embed_dim),\n",
    "            nn.ELU()\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder_net = nn.Sequential(\n",
    "            nn.Linear(self.state_dim, hidden_dim),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ELU()\n",
    "        )\n",
    "        self.decoder_mean = nn.Linear(hidden_dim // 2, obs_dim)\n",
    "        self.decoder_log_std = nn.Linear(hidden_dim // 2, obs_dim)\n",
    "        \n",
    "        # RSSM\n",
    "        self.gru = nn.GRUCell(stoch_dim + action_dim, deter_dim)\n",
    "        \n",
    "        self.prior_net = nn.Sequential(\n",
    "            nn.Linear(deter_dim, hidden_dim),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_dim, stoch_dim * 2)\n",
    "        )\n",
    "        \n",
    "        self.posterior_net = nn.Sequential(\n",
    "            nn.Linear(deter_dim + embed_dim, hidden_dim),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_dim, stoch_dim * 2)\n",
    "        )\n",
    "        \n",
    "        # Reward predictor\n",
    "        self.reward_pred = nn.Sequential(\n",
    "            nn.Linear(self.state_dim, hidden_dim // 2),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_dim // 2, 1)\n",
    "        )\n",
    "    \n",
    "    def initial_state(self, batch_size: int, device: torch.device) -> Dict[str, Tensor]:\n",
    "        return {\n",
    "            'deter': torch.zeros(batch_size, self.deter_dim, device=device),\n",
    "            'stoch': torch.zeros(batch_size, self.stoch_dim, device=device)\n",
    "        }\n",
    "    \n",
    "    def get_full_state(self, state: Dict[str, Tensor]) -> Tensor:\n",
    "        return torch.cat([state['deter'], state['stoch']], dim=-1)\n",
    "    \n",
    "    def forward(self, obs_seq: Tensor, action_seq: Tensor) -> Dict[str, Tensor]:\n",
    "        batch_size, seq_len = obs_seq.shape[:2]\n",
    "        device = obs_seq.device\n",
    "        \n",
    "        state = self.initial_state(batch_size, device)\n",
    "        \n",
    "        states = []\n",
    "        prior_means, prior_stds = [], []\n",
    "        post_means, post_stds = [], []\n",
    "        \n",
    "        for t in range(seq_len):\n",
    "            # Encode\n",
    "            embed = self.encoder(obs_seq[:, t])\n",
    "            \n",
    "            # Update deterministic\n",
    "            gru_input = torch.cat([state['stoch'], action_seq[:, t]], dim=-1)\n",
    "            deter = self.gru(gru_input, state['deter'])\n",
    "            \n",
    "            # Prior\n",
    "            prior_stats = self.prior_net(deter)\n",
    "            prior_mean, prior_log_std = torch.chunk(prior_stats, 2, dim=-1)\n",
    "            prior_std = F.softplus(prior_log_std) + 0.1\n",
    "            \n",
    "            # Posterior\n",
    "            post_input = torch.cat([deter, embed], dim=-1)\n",
    "            post_stats = self.posterior_net(post_input)\n",
    "            post_mean, post_log_std = torch.chunk(post_stats, 2, dim=-1)\n",
    "            post_std = F.softplus(post_log_std) + 0.1\n",
    "            \n",
    "            # Sample\n",
    "            stoch = post_mean + post_std * torch.randn_like(post_std)\n",
    "            \n",
    "            state = {'deter': deter, 'stoch': stoch}\n",
    "            \n",
    "            states.append(self.get_full_state(state))\n",
    "            prior_means.append(prior_mean)\n",
    "            prior_stds.append(prior_std)\n",
    "            post_means.append(post_mean)\n",
    "            post_stds.append(post_std)\n",
    "        \n",
    "        states = torch.stack(states, dim=1)\n",
    "        \n",
    "        # Decode\n",
    "        flat_states = states.reshape(-1, states.shape[-1])\n",
    "        dec_hidden = self.decoder_net(flat_states)\n",
    "        obs_mean = self.decoder_mean(dec_hidden).reshape(batch_size, seq_len, -1)\n",
    "        obs_log_std = self.decoder_log_std(dec_hidden).clamp(-10, 2).reshape(batch_size, seq_len, -1)\n",
    "        \n",
    "        reward_pred = self.reward_pred(flat_states).reshape(batch_size, seq_len)\n",
    "        \n",
    "        return {\n",
    "            'states': states,\n",
    "            'obs_mean': obs_mean,\n",
    "            'obs_log_std': obs_log_std,\n",
    "            'reward_pred': reward_pred,\n",
    "            'prior_mean': torch.stack(prior_means, dim=1),\n",
    "            'prior_std': torch.stack(prior_stds, dim=1),\n",
    "            'post_mean': torch.stack(post_means, dim=1),\n",
    "            'post_std': torch.stack(post_stds, dim=1)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardTrainer:\n",
    "    \"\"\"Standard trainer for comparison.\"\"\"\n",
    "    \n",
    "    def __init__(self, model, learning_rate=3e-4, kl_weight=1.0, free_nats=3.0):\n",
    "        self.model = model\n",
    "        self.kl_weight = kl_weight\n",
    "        self.free_nats = free_nats\n",
    "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "        self.logger = MetricLogger(name='standard')\n",
    "    \n",
    "    def train_step(self, obs_seq, action_seq, reward_seq):\n",
    "        self.model.train()\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        outputs = self.model(obs_seq, action_seq)\n",
    "        \n",
    "        # Reconstruction loss\n",
    "        obs_dist = torch.distributions.Normal(outputs['obs_mean'], torch.exp(outputs['obs_log_std']))\n",
    "        recon_loss = -obs_dist.log_prob(obs_seq).mean()\n",
    "        \n",
    "        # KL loss\n",
    "        prior_dist = torch.distributions.Normal(outputs['prior_mean'], outputs['prior_std'])\n",
    "        post_dist = torch.distributions.Normal(outputs['post_mean'], outputs['post_std'])\n",
    "        kl_div = torch.distributions.kl_divergence(post_dist, prior_dist)\n",
    "        kl_loss = torch.maximum(kl_div.mean(), torch.tensor(self.free_nats, device=kl_div.device))\n",
    "        \n",
    "        # Reward loss\n",
    "        reward_loss = F.mse_loss(outputs['reward_pred'], reward_seq)\n",
    "        \n",
    "        total_loss = recon_loss + self.kl_weight * kl_loss + reward_loss\n",
    "        \n",
    "        total_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), 100.0)\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        metrics = {\n",
    "            'recon_loss': recon_loss.item(),\n",
    "            'kl_loss': kl_loss.item(),\n",
    "            'reward_loss': reward_loss.item(),\n",
    "            'total_loss': total_loss.item()\n",
    "        }\n",
    "        \n",
    "        for key, value in metrics.items():\n",
    "            self.logger.log(**{key: value})\n",
    "        \n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_comparison(\n",
    "    env_name: str = 'CartPole-v1',\n",
    "    num_episodes: int = 20,\n",
    "    num_epochs: int = 50,\n",
    "    batch_size: int = 32,\n",
    "    seq_len: int = 20,\n",
    "    seed: int = 42\n",
    ") -> Dict[str, List[float]]:\n",
    "    \"\"\"\n",
    "    Run comparison between gate-enhanced and standard world models.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    env_name : str\n",
    "        Environment name\n",
    "    num_episodes : int\n",
    "        Number of episodes to collect\n",
    "    num_epochs : int\n",
    "        Number of training epochs\n",
    "    batch_size : int\n",
    "        Batch size\n",
    "    seq_len : int\n",
    "        Sequence length\n",
    "    seed : int\n",
    "        Random seed\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, List[float]]\n",
    "        Training histories for both models\n",
    "    \"\"\"\n",
    "    set_seed(seed)\n",
    "    \n",
    "    print(f\"Collecting {num_episodes} episodes from {env_name}...\")\n",
    "    episodes = collect_episodes(env_name, num_episodes)\n",
    "    \n",
    "    # Get dimensions - handle both 1D and 2D action arrays\n",
    "    obs_dim = episodes[0]['obs'].shape[1]\n",
    "    action_shape = episodes[0]['actions'].shape\n",
    "    action_dim = action_shape[1] if len(action_shape) > 1 else 1\n",
    "    \n",
    "    print(f\"Observation dim: {obs_dim}, Action dim: {action_dim}\")\n",
    "    print(f\"Creating training batches...\")\n",
    "    \n",
    "    batches = create_batches(episodes, batch_size, seq_len)\n",
    "    print(f\"Created {len(batches)} batches\")\n",
    "    \n",
    "    # Create models\n",
    "    print(\"\\nInitializing models...\")\n",
    "    \n",
    "    gate_model = GateEnhancedWorldModel(obs_dim, action_dim).to(device)\n",
    "    standard_model = StandardWorldModel(obs_dim, action_dim).to(device)\n",
    "    \n",
    "    gate_params = sum(p.numel() for p in gate_model.parameters())\n",
    "    standard_params = sum(p.numel() for p in standard_model.parameters())\n",
    "    print(f\"Gate-enhanced parameters: {gate_params:,}\")\n",
    "    print(f\"Standard parameters: {standard_params:,}\")\n",
    "    \n",
    "    # Create trainers\n",
    "    gate_trainer = GateEnhancedTrainer(gate_model)\n",
    "    standard_trainer = StandardTrainer(standard_model)\n",
    "    \n",
    "    # Training histories\n",
    "    histories = {\n",
    "        'gate_loss': [],\n",
    "        'standard_loss': [],\n",
    "        'gate_recon': [],\n",
    "        'standard_recon': []\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nTraining for {num_epochs} epochs...\")\n",
    "    timer = Timer().start()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        gate_losses, standard_losses = [], []\n",
    "        gate_recons, standard_recons = [], []\n",
    "        \n",
    "        for obs, actions, rewards in batches:\n",
    "            # Train gate-enhanced\n",
    "            gate_metrics = gate_trainer.train_step(obs, actions, rewards)\n",
    "            gate_losses.append(gate_metrics['total_loss'])\n",
    "            gate_recons.append(gate_metrics['recon_loss'])\n",
    "            \n",
    "            # Train standard\n",
    "            standard_metrics = standard_trainer.train_step(obs, actions, rewards)\n",
    "            standard_losses.append(standard_metrics['total_loss'])\n",
    "            standard_recons.append(standard_metrics['recon_loss'])\n",
    "        \n",
    "        # Record epoch averages\n",
    "        histories['gate_loss'].append(np.mean(gate_losses))\n",
    "        histories['standard_loss'].append(np.mean(standard_losses))\n",
    "        histories['gate_recon'].append(np.mean(gate_recons))\n",
    "        histories['standard_recon'].append(np.mean(standard_recons))\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "            print(f\"  Gate-enhanced loss: {histories['gate_loss'][-1]:.4f}\")\n",
    "            print(f\"  Standard loss: {histories['standard_loss'][-1]:.4f}\")\n",
    "    \n",
    "    elapsed = timer.stop()\n",
    "    print(f\"\\nTraining completed in {elapsed:.2f}s\")\n",
    "    \n",
    "    return histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting 20 episodes from CartPole-v1...\n",
      "Observation dim: 4, Action dim: 1\n",
      "Creating training batches...\n",
      "Created 1 batches\n",
      "\n",
      "Initializing models...\n",
      "Gate-enhanced parameters: 330,706\n",
      "Standard parameters: 291,529\n",
      "\n",
      "Training for 50 epochs...\n",
      "Epoch 10/50:\n",
      "  Gate-enhanced loss: 3.8447\n",
      "  Standard loss: 4.8044\n",
      "Epoch 20/50:\n",
      "  Gate-enhanced loss: 3.0132\n",
      "  Standard loss: 4.5764\n",
      "Epoch 30/50:\n",
      "  Gate-enhanced loss: 2.4946\n",
      "  Standard loss: 4.2177\n",
      "Epoch 40/50:\n",
      "  Gate-enhanced loss: 2.1724\n",
      "  Standard loss: 3.8061\n",
      "Epoch 50/50:\n",
      "  Gate-enhanced loss: 1.9293\n",
      "  Standard loss: 3.5670\n",
      "\n",
      "Training completed in 21.25s\n"
     ]
    }
   ],
   "source": [
    "# Run comparison\n",
    "histories = run_comparison(\n",
    "    env_name='CartPole-v1',\n",
    "    num_episodes=100,\n",
    "    num_epochs=50,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Final Comparison (last 10 epochs average):\n",
      "============================================================\n",
      "Gate-enhanced total loss: 2.0223\n",
      "Standard total loss: 3.6595\n",
      "Gate-enhanced recon loss: -0.9951\n",
      "Standard recon loss: 0.5600\n"
     ]
    }
   ],
   "source": [
    "# Visualize comparison\n",
    "import os\n",
    "os.makedirs('../results/figures', exist_ok=True)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Total loss\n",
    "ax = axes[0]\n",
    "ax.plot(histories['gate_loss'], label='Gate-Enhanced', color=COLORS['gates'], linewidth=2)\n",
    "ax.plot(histories['standard_loss'], label='Standard', color=COLORS['baseline'], linewidth=2)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Total Loss')\n",
    "ax.set_title('Total Loss Comparison')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Reconstruction loss\n",
    "ax = axes[1]\n",
    "ax.plot(histories['gate_recon'], label='Gate-Enhanced', color=COLORS['gates'], linewidth=2)\n",
    "ax.plot(histories['standard_recon'], label='Standard', color=COLORS['baseline'], linewidth=2)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Reconstruction Loss')\n",
    "ax.set_title('Reconstruction Loss Comparison')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/gate_enhanced_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Final Comparison (last 10 epochs average):\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Gate-enhanced total loss: {np.mean(histories['gate_loss'][-10:]):.4f}\")\n",
    "print(f\"Standard total loss: {np.mean(histories['standard_loss'][-10:]):.4f}\")\n",
    "print(f\"Gate-enhanced recon loss: {np.mean(histories['gate_recon'][-10:]):.4f}\")\n",
    "print(f\"Standard recon loss: {np.mean(histories['standard_recon'][-10:]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.11 Dissertation Metrics: Test Set Evaluation\n",
    "\n",
    "Evaluate models on held-out test data for unbiased performance assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test set for evaluation...\n",
      "Collected 50 episodes, created 4 test batches\n",
      "\n",
      "Evaluating on test set...\n",
      "Training batches: 2\n",
      "\n",
      "Test Set Results:\n",
      "  Gate-Enhanced MSE: 0.016667 +/- 0.000804\n",
      "  Standard MSE:      0.239037 +/- 0.025482\n"
     ]
    }
   ],
   "source": [
    "def evaluate_on_test_set(model, test_batches, device):\n",
    "    \"\"\"\n",
    "    Evaluate model on test set for dissertation metrics.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dict with test_mse, test_mae, and prediction_accuracy\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_mse = []\n",
    "    all_mae = []\n",
    "    \n",
    "    if len(test_batches) == 0:\n",
    "        return {\n",
    "            'test_mse': float('nan'),\n",
    "            'test_mae': float('nan'),\n",
    "            'test_mse_std': float('nan'),\n",
    "            'test_mae_std': float('nan')\n",
    "        }\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for obs, actions, rewards in test_batches:\n",
    "            outputs = model(obs, actions)\n",
    "            \n",
    "            # Reconstruction MSE\n",
    "            mse = F.mse_loss(outputs['obs_mean'], obs).item()\n",
    "            mae = F.l1_loss(outputs['obs_mean'], obs).item()\n",
    "            \n",
    "            all_mse.append(mse)\n",
    "            all_mae.append(mae)\n",
    "    \n",
    "    return {\n",
    "        'test_mse': np.mean(all_mse),\n",
    "        'test_mae': np.mean(all_mae),\n",
    "        'test_mse_std': np.std(all_mse),\n",
    "        'test_mae_std': np.std(all_mae)\n",
    "    }\n",
    "\n",
    "\n",
    "def calculate_sample_efficiency(histories, target_loss=None):\n",
    "    \"\"\"\n",
    "    Calculate sample efficiency: steps to reach target performance.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    histories : Dict with loss arrays\n",
    "    target_loss : float, optional\n",
    "        Target loss to reach (default: 90% of best final loss)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dict with steps_to_target for each method\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for method in ['gate', 'standard']:\n",
    "        losses = histories[f'{method}_loss']\n",
    "        \n",
    "        if target_loss is None:\n",
    "            # Target = best final loss * 1.1 (10% above optimal)\n",
    "            best_loss = min(losses[-10:])\n",
    "            target = best_loss * 1.1\n",
    "        else:\n",
    "            target = target_loss\n",
    "        \n",
    "        # Find first epoch where loss < target\n",
    "        steps_to_target = len(losses)  # Default: didn't reach\n",
    "        for i, loss in enumerate(losses):\n",
    "            if loss <= target:\n",
    "                steps_to_target = i + 1\n",
    "                break\n",
    "        \n",
    "        results[f'{method}_steps_to_target'] = steps_to_target\n",
    "        results[f'{method}_final_loss'] = losses[-1] if losses else float('inf')\n",
    "        results[f'{method}_target'] = target\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Create test set for evaluation - use more episodes to ensure we get valid batches\n",
    "print(\"Creating test set for evaluation...\")\n",
    "test_episodes = collect_episodes('CartPole-v1', num_episodes=100)  # Increased from 5 to 50\n",
    "test_batches = create_batches(test_episodes, batch_size=32, seq_len=20)\n",
    "print(f\"Collected {len(test_episodes)} episodes, created {len(test_batches)} test batches\")\n",
    "\n",
    "if len(test_batches) == 0:\n",
    "    print(\"WARNING: No test batches created. Skipping test evaluation demo.\")\n",
    "else:\n",
    "    # Evaluate both models\n",
    "    print(\"\\nEvaluating on test set...\")\n",
    "    gate_model = GateEnhancedWorldModel(obs_dim=4, action_dim=1).to(device)\n",
    "    standard_model = StandardWorldModel(obs_dim=4, action_dim=1).to(device)\n",
    "\n",
    "    # Quick training to get comparable models\n",
    "    gate_trainer = GateEnhancedTrainer(gate_model)\n",
    "    standard_trainer = StandardTrainer(standard_model)\n",
    "\n",
    "    train_episodes = collect_episodes('CartPole-v1', num_episodes=100)\n",
    "    train_batches = create_batches(train_episodes, batch_size=32, seq_len=20)\n",
    "    print(f\"Training batches: {len(train_batches)}\")\n",
    "\n",
    "    for epoch in range(50):\n",
    "        for obs, actions, rewards in train_batches:\n",
    "            gate_trainer.train_step(obs, actions, rewards)\n",
    "            standard_trainer.train_step(obs, actions, rewards)\n",
    "\n",
    "    # Test evaluation\n",
    "    gate_test_metrics = evaluate_on_test_set(gate_model, test_batches, device)\n",
    "    standard_test_metrics = evaluate_on_test_set(standard_model, test_batches, device)\n",
    "\n",
    "    print(\"\\nTest Set Results:\")\n",
    "    print(f\"  Gate-Enhanced MSE: {gate_test_metrics['test_mse']:.6f} +/- {gate_test_metrics['test_mse_std']:.6f}\")\n",
    "    print(f\"  Standard MSE:      {standard_test_metrics['test_mse']:.6f} +/- {standard_test_metrics['test_mse_std']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.12 Multi-Seed Statistical Comparison\n",
    "\n",
    "Run comparison across 5 different random seeds for robust statistical analysis.\n",
    "This addresses dissertation requirements for reproducibility and statistical rigor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Seed Comparison: Gate-Enhanced vs Standard\n",
      "============================================================\n",
      "Seeds: [42, 123, 456, 789, 1024]\n",
      "Environment: CartPole-v1\n",
      "Epochs: 50, Episodes: 50 (for more reliable batches)\n"
     ]
    }
   ],
   "source": [
    "# Multi-seed setup - define helper functions\n",
    "import time\n",
    "from scipy import stats\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def run_single_seed_experiment(seed, env_name='CartPole-v1', num_episodes=100, \n",
    "                                num_epochs=50, batch_size=32, seq_len=20):\n",
    "    \"\"\"Run a single seed experiment for both methods.\"\"\"\n",
    "    set_seed(seed)\n",
    "    \n",
    "    # Collect data - use more episodes to ensure we get batches\n",
    "    episodes = collect_episodes(env_name, num_episodes)\n",
    "    if len(episodes) == 0:\n",
    "        print(f\"  WARNING: No episodes collected for seed {seed}\")\n",
    "        return None\n",
    "    \n",
    "    obs_dim = episodes[0]['obs'].shape[1]\n",
    "    # Handle both 1D and 2D action arrays\n",
    "    action_shape = episodes[0]['actions'].shape\n",
    "    action_dim = action_shape[1] if len(action_shape) > 1 else 1\n",
    "    batches = create_batches(episodes, batch_size, seq_len)\n",
    "    \n",
    "    if len(batches) == 0:\n",
    "        print(f\"  WARNING: No batches created for seed {seed}\")\n",
    "        return None\n",
    "    \n",
    "    # Create models\n",
    "    gate_model = GateEnhancedWorldModel(obs_dim, action_dim).to(device)\n",
    "    standard_model = StandardWorldModel(obs_dim, action_dim).to(device)\n",
    "    \n",
    "    gate_trainer = GateEnhancedTrainer(gate_model)\n",
    "    standard_trainer = StandardTrainer(standard_model)\n",
    "    \n",
    "    # Training\n",
    "    gate_losses, standard_losses = [], []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        g_epoch_loss, s_epoch_loss = [], []\n",
    "        for obs, actions, rewards in batches:\n",
    "            g_metrics = gate_trainer.train_step(obs, actions, rewards)\n",
    "            s_metrics = standard_trainer.train_step(obs, actions, rewards)\n",
    "            g_epoch_loss.append(g_metrics['total_loss'])\n",
    "            s_epoch_loss.append(s_metrics['total_loss'])\n",
    "        gate_losses.append(np.mean(g_epoch_loss))\n",
    "        standard_losses.append(np.mean(s_epoch_loss))\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # Test evaluation - use more episodes\n",
    "    test_episodes = collect_episodes(env_name, num_episodes=100)\n",
    "    test_batches = create_batches(test_episodes, batch_size, seq_len)\n",
    "    \n",
    "    gate_test = evaluate_on_test_set(gate_model, test_batches, device)\n",
    "    standard_test = evaluate_on_test_set(standard_model, test_batches, device)\n",
    "    \n",
    "    return {\n",
    "        'seed': seed,\n",
    "        'gate_final_loss': gate_losses[-1],\n",
    "        'standard_final_loss': standard_losses[-1],\n",
    "        'gate_test_mse': gate_test['test_mse'],\n",
    "        'standard_test_mse': standard_test['test_mse'],\n",
    "        'gate_losses': gate_losses,\n",
    "        'standard_losses': standard_losses,\n",
    "        'time': elapsed_time,\n",
    "        'gate_params': sum(p.numel() for p in gate_model.parameters()),\n",
    "        'standard_params': sum(p.numel() for p in standard_model.parameters())\n",
    "    }\n",
    "\n",
    "\n",
    "def convert_to_serializable(obj):\n",
    "    \"\"\"Convert numpy types to Python native types for JSON serialization.\"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: convert_to_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_serializable(item) for item in obj]\n",
    "    elif isinstance(obj, (np.bool_, bool)):\n",
    "        return bool(obj)\n",
    "    elif isinstance(obj, (np.floating, float)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, (np.integer, int)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    return obj\n",
    "\n",
    "\n",
    "# Setup\n",
    "SEEDS = [42, 123, 456, 789, 1024]\n",
    "print(\"Multi-Seed Comparison: Gate-Enhanced vs Standard\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Seeds: {SEEDS}\")\n",
    "print(f\"Environment: CartPole-v1\")\n",
    "print(f\"Epochs: 50, Episodes: 50 (for more reliable batches)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Seed 42...\n",
      "  Gate loss: 1.4399, Standard loss: 2.2660\n",
      "  Gate test MSE: 0.002834, Standard test MSE: 0.032883\n",
      "  Time: 63.2s\n"
     ]
    }
   ],
   "source": [
    "# Seed 1: 42\n",
    "print(\"Running Seed 42...\")\n",
    "result_seed_42 = run_single_seed_experiment(42)\n",
    "print(f\"  Gate loss: {result_seed_42['gate_final_loss']:.4f}, Standard loss: {result_seed_42['standard_final_loss']:.4f}\")\n",
    "print(f\"  Gate test MSE: {result_seed_42['gate_test_mse']:.6f}, Standard test MSE: {result_seed_42['standard_test_mse']:.6f}\")\n",
    "print(f\"  Time: {result_seed_42['time']:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Seed 123...\n",
      "  Gate loss: 1.0621, Standard loss: 2.2604\n",
      "  Gate test MSE: 0.002606, Standard test MSE: 0.048118\n",
      "  Time: 62.8s\n"
     ]
    }
   ],
   "source": [
    "# Seed 2: 123\n",
    "print(\"Running Seed 123...\")\n",
    "result_seed_123 = run_single_seed_experiment(123)\n",
    "print(f\"  Gate loss: {result_seed_123['gate_final_loss']:.4f}, Standard loss: {result_seed_123['standard_final_loss']:.4f}\")\n",
    "print(f\"  Gate test MSE: {result_seed_123['gate_test_mse']:.6f}, Standard test MSE: {result_seed_123['standard_test_mse']:.6f}\")\n",
    "print(f\"  Time: {result_seed_123['time']:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Seed 456...\n",
      "  Gate loss: 0.8215, Standard loss: 1.9055\n",
      "  Gate test MSE: 0.001666, Standard test MSE: 0.009933\n",
      "  Time: 83.3s\n"
     ]
    }
   ],
   "source": [
    "# Seed 3: 456\n",
    "print(\"Running Seed 456...\")\n",
    "result_seed_456 = run_single_seed_experiment(456)\n",
    "print(f\"  Gate loss: {result_seed_456['gate_final_loss']:.4f}, Standard loss: {result_seed_456['standard_final_loss']:.4f}\")\n",
    "print(f\"  Gate test MSE: {result_seed_456['gate_test_mse']:.6f}, Standard test MSE: {result_seed_456['standard_test_mse']:.6f}\")\n",
    "print(f\"  Time: {result_seed_456['time']:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Seed 789...\n",
      "  Gate loss: 1.0330, Standard loss: 1.9099\n",
      "  Gate test MSE: 0.001469, Standard test MSE: 0.009190\n",
      "  Time: 84.0s\n"
     ]
    }
   ],
   "source": [
    "# Seed 4: 789\n",
    "print(\"Running Seed 789...\")\n",
    "result_seed_789 = run_single_seed_experiment(789)\n",
    "print(f\"  Gate loss: {result_seed_789['gate_final_loss']:.4f}, Standard loss: {result_seed_789['standard_final_loss']:.4f}\")\n",
    "print(f\"  Gate test MSE: {result_seed_789['gate_test_mse']:.6f}, Standard test MSE: {result_seed_789['standard_test_mse']:.6f}\")\n",
    "print(f\"  Time: {result_seed_789['time']:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Seed 1024...\n",
      "  Gate loss: 0.8818, Standard loss: 1.9324\n",
      "  Gate test MSE: 0.002752, Standard test MSE: 0.020989\n",
      "  Time: 83.5s\n"
     ]
    }
   ],
   "source": [
    "# Seed 5: 1024\n",
    "print(\"Running Seed 1024...\")\n",
    "result_seed_1024 = run_single_seed_experiment(1024)\n",
    "print(f\"  Gate loss: {result_seed_1024['gate_final_loss']:.4f}, Standard loss: {result_seed_1024['standard_final_loss']:.4f}\")\n",
    "print(f\"  Gate test MSE: {result_seed_1024['gate_test_mse']:.6f}, Standard test MSE: {result_seed_1024['standard_test_mse']:.6f}\")\n",
    "print(f\"  Time: {result_seed_1024['time']:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.13 Statistical Analysis\n",
    "\n",
    "Perform rigorous statistical comparison with Mann-Whitney U test, Cohen's d effect size,\n",
    "and Bonferroni correction for multiple comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid results from 5/5 seeds\n",
      "\n",
      "Aggregated Results Across Seeds\n",
      "============================================================\n",
      "\n",
      "Gate-Enhanced:\n",
      "  Final Loss: 1.0477 +/- 0.2158\n",
      "  Test MSE:   0.002265 +/- 0.000578\n",
      "\n",
      "Standard:\n",
      "  Final Loss: 2.0548 +/- 0.1704\n",
      "  Test MSE:   0.024223 +/- 0.014742\n",
      "\n",
      "============================================================\n",
      "Statistical Tests\n",
      "============================================================\n",
      "\n",
      "Bonferroni-corrected alpha: 0.0250\n",
      "\n",
      "1. Final Loss Comparison (Gate vs Standard)\n",
      "   Mann-Whitney U statistic: 0.0000\n",
      "   p-value: 0.007937\n",
      "   Cohen's d: -4.6329\n",
      "   Significant (Bonferroni): True\n",
      "   Winner: Gate-Enhanced\n",
      "\n",
      "2. Test MSE Comparison (Gate vs Standard)\n",
      "   Mann-Whitney U statistic: 0.0000\n",
      "   p-value: 0.007937\n",
      "   Cohen's d: -1.8826\n",
      "   Significant (Bonferroni): True\n",
      "   Winner: Gate-Enhanced\n",
      "\n",
      "============================================================\n",
      "95% Confidence Intervals\n",
      "============================================================\n",
      "\n",
      "Final Loss:\n",
      "  Gate-Enhanced: [0.7480, 1.3473]\n",
      "  Standard:      [1.8183, 2.2914]\n",
      "\n",
      "Test MSE:\n",
      "  Gate-Enhanced: [0.001463, 0.003068]\n",
      "  Standard:      [0.003757, 0.044688]\n"
     ]
    }
   ],
   "source": [
    "# Aggregate results from all seeds - filter out None results\n",
    "all_results_raw = [result_seed_42, result_seed_123, result_seed_456, result_seed_789, result_seed_1024]\n",
    "all_results = [r for r in all_results_raw if r is not None]\n",
    "\n",
    "if len(all_results) == 0:\n",
    "    print(\"ERROR: No valid results from any seed!\")\n",
    "else:\n",
    "    print(f\"Valid results from {len(all_results)}/{len(all_results_raw)} seeds\")\n",
    "    \n",
    "    gate_final_losses = [r['gate_final_loss'] for r in all_results]\n",
    "    standard_final_losses = [r['standard_final_loss'] for r in all_results]\n",
    "    gate_test_mses = [r['gate_test_mse'] for r in all_results if not np.isnan(r['gate_test_mse'])]\n",
    "    standard_test_mses = [r['standard_test_mse'] for r in all_results if not np.isnan(r['standard_test_mse'])]\n",
    "\n",
    "    print(\"\\nAggregated Results Across Seeds\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nGate-Enhanced:\")\n",
    "    print(f\"  Final Loss: {np.mean(gate_final_losses):.4f} +/- {np.std(gate_final_losses):.4f}\")\n",
    "    if len(gate_test_mses) > 0:\n",
    "        print(f\"  Test MSE:   {np.mean(gate_test_mses):.6f} +/- {np.std(gate_test_mses):.6f}\")\n",
    "    else:\n",
    "        print(f\"  Test MSE:   No valid test results\")\n",
    "\n",
    "    print(f\"\\nStandard:\")\n",
    "    print(f\"  Final Loss: {np.mean(standard_final_losses):.4f} +/- {np.std(standard_final_losses):.4f}\")\n",
    "    if len(standard_test_mses) > 0:\n",
    "        print(f\"  Test MSE:   {np.mean(standard_test_mses):.6f} +/- {np.std(standard_test_mses):.6f}\")\n",
    "    else:\n",
    "        print(f\"  Test MSE:   No valid test results\")\n",
    "\n",
    "\n",
    "def cohens_d(group1, group2):\n",
    "    \"\"\"Calculate Cohen's d effect size.\"\"\"\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    if n1 < 2 or n2 < 2:\n",
    "        return 0.0\n",
    "    var1, var2 = np.var(group1, ddof=1), np.var(group2, ddof=1)\n",
    "    pooled_std = np.sqrt(((n1-1)*var1 + (n2-1)*var2) / (n1+n2-2))\n",
    "    return (np.mean(group1) - np.mean(group2)) / pooled_std if pooled_std > 0 else 0\n",
    "\n",
    "\n",
    "def calculate_ci_95(data):\n",
    "    \"\"\"Calculate 95% confidence interval.\"\"\"\n",
    "    n = len(data)\n",
    "    if n < 2:\n",
    "        return (float('nan'), float('nan'))\n",
    "    mean = np.mean(data)\n",
    "    se = stats.sem(data)\n",
    "    ci = stats.t.interval(0.95, n-1, loc=mean, scale=se)\n",
    "    return ci\n",
    "\n",
    "\n",
    "# Statistical Tests\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Statistical Tests\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if len(all_results) >= 2:\n",
    "    # Bonferroni correction for 2 comparisons\n",
    "    bonferroni_alpha = 0.05 / 2  # Two comparisons: loss and MSE\n",
    "    print(f\"\\nBonferroni-corrected alpha: {bonferroni_alpha:.4f}\")\n",
    "\n",
    "    # Test 1: Final Loss comparison\n",
    "    u_stat_loss, p_value_loss = stats.mannwhitneyu(gate_final_losses, standard_final_losses, alternative='two-sided')\n",
    "    d_loss = cohens_d(gate_final_losses, standard_final_losses)\n",
    "\n",
    "    print(\"\\n1. Final Loss Comparison (Gate vs Standard)\")\n",
    "    print(f\"   Mann-Whitney U statistic: {u_stat_loss:.4f}\")\n",
    "    print(f\"   p-value: {p_value_loss:.6f}\")\n",
    "    print(f\"   Cohen's d: {d_loss:.4f}\")\n",
    "    print(f\"   Significant (Bonferroni): {bool(p_value_loss < bonferroni_alpha)}\")\n",
    "    print(f\"   Winner: {'Gate-Enhanced' if np.mean(gate_final_losses) < np.mean(standard_final_losses) else 'Standard'}\")\n",
    "\n",
    "    # Test 2: Test MSE comparison (if we have valid data)\n",
    "    if len(gate_test_mses) >= 2 and len(standard_test_mses) >= 2:\n",
    "        u_stat_mse, p_value_mse = stats.mannwhitneyu(gate_test_mses, standard_test_mses, alternative='two-sided')\n",
    "        d_mse = cohens_d(gate_test_mses, standard_test_mses)\n",
    "\n",
    "        print(\"\\n2. Test MSE Comparison (Gate vs Standard)\")\n",
    "        print(f\"   Mann-Whitney U statistic: {u_stat_mse:.4f}\")\n",
    "        print(f\"   p-value: {p_value_mse:.6f}\")\n",
    "        print(f\"   Cohen's d: {d_mse:.4f}\")\n",
    "        print(f\"   Significant (Bonferroni): {bool(p_value_mse < bonferroni_alpha)}\")\n",
    "        print(f\"   Winner: {'Gate-Enhanced' if np.mean(gate_test_mses) < np.mean(standard_test_mses) else 'Standard'}\")\n",
    "    else:\n",
    "        print(\"\\n2. Test MSE Comparison: Insufficient data\")\n",
    "        p_value_mse = float('nan')\n",
    "        d_mse = 0.0\n",
    "\n",
    "    # 95% Confidence Intervals\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"95% Confidence Intervals\")\n",
    "    print(\"=\" * 60)\n",
    "    gate_loss_ci = calculate_ci_95(gate_final_losses)\n",
    "    standard_loss_ci = calculate_ci_95(standard_final_losses)\n",
    "    \n",
    "    print(f\"\\nFinal Loss:\")\n",
    "    print(f\"  Gate-Enhanced: [{gate_loss_ci[0]:.4f}, {gate_loss_ci[1]:.4f}]\")\n",
    "    print(f\"  Standard:      [{standard_loss_ci[0]:.4f}, {standard_loss_ci[1]:.4f}]\")\n",
    "    \n",
    "    if len(gate_test_mses) >= 2 and len(standard_test_mses) >= 2:\n",
    "        gate_mse_ci = calculate_ci_95(gate_test_mses)\n",
    "        standard_mse_ci = calculate_ci_95(standard_test_mses)\n",
    "        print(f\"\\nTest MSE:\")\n",
    "        print(f\"  Gate-Enhanced: [{gate_mse_ci[0]:.6f}, {gate_mse_ci[1]:.6f}]\")\n",
    "        print(f\"  Standard:      [{standard_mse_ci[0]:.6f}, {standard_mse_ci[1]:.6f}]\")\n",
    "    else:\n",
    "        gate_mse_ci = (float('nan'), float('nan'))\n",
    "        standard_mse_ci = (float('nan'), float('nan'))\n",
    "else:\n",
    "    print(\"Insufficient data for statistical tests (need at least 2 valid seeds)\")\n",
    "    bonferroni_alpha = 0.025\n",
    "    p_value_loss = float('nan')\n",
    "    p_value_mse = float('nan')\n",
    "    d_loss = 0.0\n",
    "    d_mse = 0.0\n",
    "    gate_loss_ci = (float('nan'), float('nan'))\n",
    "    standard_loss_ci = (float('nan'), float('nan'))\n",
    "    gate_mse_ci = (float('nan'), float('nan'))\n",
    "    standard_mse_ci = (float('nan'), float('nan'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.14 Complete Metrics Summary and Results Saving\n",
    "\n",
    "Compile all dissertation metrics and save results to JSON for later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "COMPLETE DISSERTATION METRICS SUMMARY\n",
      "Phase 5: Gate-Enhanced Neural Layers\n",
      "======================================================================\n",
      "\n",
      "1. SAMPLE EFFICIENCY (epochs to target)\n",
      "----------------------------------------\n",
      "   Target loss: 1.1243\n",
      "   Gate-Enhanced: 40 epochs\n",
      "   Standard: 50 epochs\n",
      "\n",
      "2. TRAINING SPEED\n",
      "----------------------------------------\n",
      "   Gate-Enhanced: 75.4s +/- 10.1s\n",
      "\n",
      "3. PREDICTION ACCURACY (Test MSE)\n",
      "----------------------------------------\n",
      "   Gate-Enhanced: 0.002265 +/- 0.000578\n",
      "   Standard:      0.024223 +/- 0.014742\n",
      "\n",
      "4. FINAL PERFORMANCE (Training Loss)\n",
      "----------------------------------------\n",
      "   Gate-Enhanced: 1.0477 +/- 0.2158\n",
      "   Standard:      2.0548 +/- 0.1704\n",
      "\n",
      "5. STABILITY (Standard Deviation across seeds)\n",
      "----------------------------------------\n",
      "   Gate-Enhanced loss std: 0.215832\n",
      "   Standard loss std:      0.170396\n",
      "\n",
      "6. COMPUTATIONAL COST\n",
      "----------------------------------------\n",
      "   Gate-Enhanced parameters: 330,706\n",
      "   Standard parameters:      291,529\n",
      "\n",
      "7. STATISTICAL SIGNIFICANCE\n",
      "----------------------------------------\n",
      "   Final Loss p-value: 0.007937 (significant: True)\n",
      "   Test MSE p-value:   0.007937 (significant: True)\n",
      "   Effect sizes: Loss d=-4.6329, MSE d=-1.8826\n",
      "\n",
      "======================================================================\n",
      "Results saved to: ..\\experiments\\results\\gates\\complete_metrics.json\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Complete dissertation metrics summary\n",
    "print(\"=\" * 70)\n",
    "print(\"COMPLETE DISSERTATION METRICS SUMMARY\")\n",
    "print(\"Phase 5: Gate-Enhanced Neural Layers\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if len(all_results) == 0:\n",
    "    print(\"\\nERROR: No valid results to summarize!\")\n",
    "else:\n",
    "    # Calculate sample efficiency from training histories\n",
    "    gate_losses_all = [r['gate_losses'] for r in all_results]\n",
    "    standard_losses_all = [r['standard_losses'] for r in all_results]\n",
    "\n",
    "    # Average training curves\n",
    "    avg_gate_curve = np.mean(gate_losses_all, axis=0)\n",
    "    avg_standard_curve = np.mean(standard_losses_all, axis=0)\n",
    "\n",
    "    # Sample efficiency: epochs to reach target (90% of best)\n",
    "    target_loss = min(avg_gate_curve[-10:].min(), avg_standard_curve[-10:].min()) * 1.1\n",
    "\n",
    "    gate_steps_to_target = len(avg_gate_curve)\n",
    "    standard_steps_to_target = len(avg_standard_curve)\n",
    "\n",
    "    for i, loss in enumerate(avg_gate_curve):\n",
    "        if loss <= target_loss:\n",
    "            gate_steps_to_target = i + 1\n",
    "            break\n",
    "\n",
    "    for i, loss in enumerate(avg_standard_curve):\n",
    "        if loss <= target_loss:\n",
    "            standard_steps_to_target = i + 1\n",
    "            break\n",
    "\n",
    "    # Training times\n",
    "    gate_times = [r['time'] for r in all_results]\n",
    "\n",
    "    print(\"\\n1. SAMPLE EFFICIENCY (epochs to target)\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"   Target loss: {target_loss:.4f}\")\n",
    "    print(f\"   Gate-Enhanced: {gate_steps_to_target} epochs\")\n",
    "    print(f\"   Standard: {standard_steps_to_target} epochs\")\n",
    "\n",
    "    print(\"\\n2. TRAINING SPEED\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"   Gate-Enhanced: {np.mean(gate_times):.1f}s +/- {np.std(gate_times):.1f}s\")\n",
    "\n",
    "    print(\"\\n3. PREDICTION ACCURACY (Test MSE)\")\n",
    "    print(\"-\" * 40)\n",
    "    if len(gate_test_mses) > 0:\n",
    "        print(f\"   Gate-Enhanced: {np.mean(gate_test_mses):.6f} +/- {np.std(gate_test_mses):.6f}\")\n",
    "    else:\n",
    "        print(f\"   Gate-Enhanced: N/A\")\n",
    "    if len(standard_test_mses) > 0:\n",
    "        print(f\"   Standard:      {np.mean(standard_test_mses):.6f} +/- {np.std(standard_test_mses):.6f}\")\n",
    "    else:\n",
    "        print(f\"   Standard:      N/A\")\n",
    "\n",
    "    print(\"\\n4. FINAL PERFORMANCE (Training Loss)\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"   Gate-Enhanced: {np.mean(gate_final_losses):.4f} +/- {np.std(gate_final_losses):.4f}\")\n",
    "    print(f\"   Standard:      {np.mean(standard_final_losses):.4f} +/- {np.std(standard_final_losses):.4f}\")\n",
    "\n",
    "    print(\"\\n5. STABILITY (Standard Deviation across seeds)\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"   Gate-Enhanced loss std: {np.std(gate_final_losses):.6f}\")\n",
    "    print(f\"   Standard loss std:      {np.std(standard_final_losses):.6f}\")\n",
    "\n",
    "    print(\"\\n6. COMPUTATIONAL COST\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"   Gate-Enhanced parameters: {all_results[0]['gate_params']:,}\")\n",
    "    print(f\"   Standard parameters:      {all_results[0]['standard_params']:,}\")\n",
    "\n",
    "    print(\"\\n7. STATISTICAL SIGNIFICANCE\")\n",
    "    print(\"-\" * 40)\n",
    "    if not np.isnan(p_value_loss):\n",
    "        print(f\"   Final Loss p-value: {p_value_loss:.6f} (significant: {bool(p_value_loss < bonferroni_alpha)})\")\n",
    "    else:\n",
    "        print(f\"   Final Loss p-value: N/A\")\n",
    "    if not np.isnan(p_value_mse):\n",
    "        print(f\"   Test MSE p-value:   {p_value_mse:.6f} (significant: {bool(p_value_mse < bonferroni_alpha)})\")\n",
    "    else:\n",
    "        print(f\"   Test MSE p-value:   N/A\")\n",
    "    print(f\"   Effect sizes: Loss d={d_loss:.4f}, MSE d={d_mse:.4f}\")\n",
    "\n",
    "    # Create results directory\n",
    "    results_dir = Path('../experiments/results/gates')\n",
    "    results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save complete metrics to JSON\n",
    "    complete_metrics = {\n",
    "        'metadata': {\n",
    "            'phase': 5,\n",
    "            'experiment': 'Gate-Enhanced Neural Layers',\n",
    "            'environment': 'CartPole-v1',\n",
    "            'num_seeds': len(all_results),\n",
    "            'seeds': [r['seed'] for r in all_results],\n",
    "            'num_epochs': 50,\n",
    "            'num_episodes': 50,\n",
    "            'batch_size': 16,\n",
    "            'seq_len': 20,\n",
    "            'bonferroni_alpha': bonferroni_alpha\n",
    "        },\n",
    "        'sample_efficiency': {\n",
    "            'target_loss': float(target_loss),\n",
    "            'gate_epochs_to_target': gate_steps_to_target,\n",
    "            'standard_epochs_to_target': standard_steps_to_target\n",
    "        },\n",
    "        'training_speed': {\n",
    "            'gate_mean_time': float(np.mean(gate_times)),\n",
    "            'gate_std_time': float(np.std(gate_times))\n",
    "        },\n",
    "        'prediction_accuracy': {\n",
    "            'gate_test_mse_mean': float(np.mean(gate_test_mses)) if gate_test_mses else None,\n",
    "            'gate_test_mse_std': float(np.std(gate_test_mses)) if gate_test_mses else None,\n",
    "            'standard_test_mse_mean': float(np.mean(standard_test_mses)) if standard_test_mses else None,\n",
    "            'standard_test_mse_std': float(np.std(standard_test_mses)) if standard_test_mses else None\n",
    "        },\n",
    "        'final_performance': {\n",
    "            'gate_loss_mean': float(np.mean(gate_final_losses)),\n",
    "            'gate_loss_std': float(np.std(gate_final_losses)),\n",
    "            'standard_loss_mean': float(np.mean(standard_final_losses)),\n",
    "            'standard_loss_std': float(np.std(standard_final_losses))\n",
    "        },\n",
    "        'stability': {\n",
    "            'gate_loss_std': float(np.std(gate_final_losses)),\n",
    "            'standard_loss_std': float(np.std(standard_final_losses))\n",
    "        },\n",
    "        'computational_cost': {\n",
    "            'gate_params': all_results[0]['gate_params'],\n",
    "            'standard_params': all_results[0]['standard_params']\n",
    "        },\n",
    "        'statistical_tests': {\n",
    "            'loss_comparison': {\n",
    "                'p_value': float(p_value_loss) if not np.isnan(p_value_loss) else None,\n",
    "                'cohens_d': float(d_loss),\n",
    "                'significant_bonferroni': bool(p_value_loss < bonferroni_alpha) if not np.isnan(p_value_loss) else False,\n",
    "                'winner': 'Gate-Enhanced' if np.mean(gate_final_losses) < np.mean(standard_final_losses) else 'Standard'\n",
    "            },\n",
    "            'mse_comparison': {\n",
    "                'p_value': float(p_value_mse) if not np.isnan(p_value_mse) else None,\n",
    "                'cohens_d': float(d_mse),\n",
    "                'significant_bonferroni': bool(p_value_mse < bonferroni_alpha) if not np.isnan(p_value_mse) else False,\n",
    "                'winner': 'Gate-Enhanced' if gate_test_mses and standard_test_mses and np.mean(gate_test_mses) < np.mean(standard_test_mses) else 'Standard'\n",
    "            }\n",
    "        },\n",
    "        'confidence_intervals': {\n",
    "            'gate_loss_ci': list(gate_loss_ci) if not np.isnan(gate_loss_ci[0]) else None,\n",
    "            'standard_loss_ci': list(standard_loss_ci) if not np.isnan(standard_loss_ci[0]) else None,\n",
    "            'gate_mse_ci': list(gate_mse_ci) if not np.isnan(gate_mse_ci[0]) else None,\n",
    "            'standard_mse_ci': list(standard_mse_ci) if not np.isnan(standard_mse_ci[0]) else None\n",
    "        },\n",
    "        'raw_results': {\n",
    "            'gate_final_losses': gate_final_losses,\n",
    "            'standard_final_losses': standard_final_losses,\n",
    "            'gate_test_mses': gate_test_mses,\n",
    "            'standard_test_mses': standard_test_mses\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Save to JSON\n",
    "    with open(results_dir / 'complete_metrics.json', 'w') as f:\n",
    "        json.dump(convert_to_serializable(complete_metrics), f, indent=2)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"Results saved to: {results_dir / 'complete_metrics.json'}\")\n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 5.14b Long-Horizon Prediction Test\n\nA critical test for world models in planning is **long-horizon prediction accuracy**.\nThis measures how well the model can predict future states many steps ahead - \nessential for model-based RL where agents need to \"imagine\" future trajectories.\n\n**Hypothesis:** Gate-enhanced layers should create richer, more orthogonal representations\nthat could improve long-horizon prediction accuracy by reducing compounding errors.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "\"\"\"\nCell: Long-Horizon Prediction Evaluation\nPurpose: Test how well models predict states many steps into the future\n\"\"\"\n\ndef evaluate_long_horizon(\n    model,\n    episodes: List,\n    horizons: List[int] = [1, 5, 10, 20],\n    num_samples: int = 50,\n    device: torch.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n) -> Dict[str, Dict[int, float]]:\n    \"\"\"\n    Evaluate long-horizon prediction accuracy.\n    \"\"\"\n    model.eval()\n    results = {'obs_mse': {}, 'reward_mse': {}}\n    \n    max_horizon = max(horizons)\n    valid_episodes = [ep for ep in episodes if len(ep['observations']) > max_horizon + 10]\n    \n    if len(valid_episodes) == 0:\n        print(\"Warning: No episodes long enough for evaluation\")\n        return results\n    \n    with torch.no_grad():\n        for horizon in horizons:\n            obs_errors = []\n            reward_errors = []\n            \n            for _ in range(num_samples):\n                # Sample a random starting point\n                ep = valid_episodes[np.random.randint(len(valid_episodes))]\n                max_start = len(ep['observations']) - horizon - 1\n                if max_start <= 0:\n                    continue\n                start_idx = np.random.randint(0, max_start)\n                \n                # Get ground truth trajectory\n                true_obs = torch.tensor(\n                    ep['observations'][start_idx:start_idx+horizon+1], \n                    dtype=torch.float32, device=device\n                ).unsqueeze(0)\n                true_actions = torch.tensor(\n                    ep['actions'][start_idx:start_idx+horizon], \n                    dtype=torch.float32, device=device\n                ).unsqueeze(0)\n                true_rewards = torch.tensor(\n                    ep['rewards'][start_idx:start_idx+horizon], \n                    dtype=torch.float32, device=device\n                ).unsqueeze(0)\n                \n                # Initialize model state from first observation\n                state = model.initial_state(1)\n                embed = model.encoder(true_obs[:, 0])\n                action_dim = true_actions.shape[-1]\n                dummy_action = torch.zeros(1, action_dim, device=device)\n                state, _, _ = model.rssm.observe_step(state, dummy_action, embed)\n                \n                # Predict forward using imagination (open-loop)\n                pred_obs_list = []\n                pred_reward_list = []\n                \n                for t in range(horizon):\n                    # Take action and imagine next state\n                    state, _ = model.rssm.imagine_step(state, true_actions[:, t])\n                    \n                    # Decode predictions\n                    pred_obs, pred_reward, _ = model.predict(state)\n                    pred_obs_list.append(pred_obs)\n                    pred_reward_list.append(pred_reward)\n                \n                # Stack predictions\n                pred_obs = torch.stack(pred_obs_list, dim=1)\n                pred_rewards = torch.stack(pred_reward_list, dim=1)\n                \n                # Compute MSE for final prediction at this horizon\n                obs_mse = F.mse_loss(pred_obs[:, -1], true_obs[:, horizon]).item()\n                reward_mse = F.mse_loss(pred_rewards[:, -1], true_rewards[:, horizon-1]).item()\n                \n                obs_errors.append(obs_mse)\n                reward_errors.append(reward_mse)\n            \n            results['obs_mse'][horizon] = np.mean(obs_errors) if obs_errors else float('nan')\n            results['reward_mse'][horizon] = np.mean(reward_errors) if reward_errors else float('nan')\n    \n    return results\n\n\n# Collect fresh episodes for evaluation\nprint(\"Collecting episodes for long-horizon evaluation...\")\nenv = gym.make('CartPole-v1')\nobs_dim = env.observation_space.shape[0]\naction_dim = env.action_space.n\n\neval_episodes = []\nfor ep_idx in range(30):\n    obs_list, act_list, rew_list = [], [], []\n    obs, _ = env.reset(seed=42+ep_idx)\n    done = False\n    while not done:\n        action = env.action_space.sample()\n        obs_list.append(obs)\n        act_oh = np.zeros(action_dim)\n        act_oh[action] = 1.0\n        act_list.append(act_oh)\n        obs, reward, terminated, truncated, _ = env.step(action)\n        rew_list.append(reward)\n        done = terminated or truncated\n    eval_episodes.append({\n        'observations': np.array(obs_list, dtype=np.float32),\n        'actions': np.array(act_list, dtype=np.float32),\n        'rewards': np.array(rew_list, dtype=np.float32)\n    })\nenv.close()\n\n# Create and train models quickly for evaluation\nprint(\"\\nTraining models for long-horizon evaluation (reduced epochs)...\")\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Quick training for long-horizon comparison\ngate_eval_model = GateEnhancedWorldModel(obs_dim, action_dim).to(device)\nstandard_eval_model = StandardWorldModel(obs_dim, action_dim).to(device)\n\ngate_trainer = GateEnhancedTrainer(gate_eval_model)\nstandard_trainer = StandardTrainer(standard_eval_model)\n\n# Train with reduced epochs\nfor epoch in tqdm(range(30), desc=\"Training for long-horizon eval\"):\n    gate_trainer.train_epoch(eval_episodes)\n    standard_trainer.train_epoch(eval_episodes)\n\n# Evaluate long-horizon\nprint(\"\\n\" + \"=\"*70)\nprint(\"Long-Horizon Prediction Evaluation\")\nprint(\"=\"*70)\n\ngate_horizon = evaluate_long_horizon(gate_eval_model, eval_episodes, horizons=[1, 5, 10, 20])\nstandard_horizon = evaluate_long_horizon(standard_eval_model, eval_episodes, horizons=[1, 5, 10, 20])\n\nprint(\"\\nLong-Horizon Prediction Results (Observation MSE):\")\nprint(\"-\"*70)\nprint(f\"{'Horizon':<10} {'Gate-Enhanced':<18} {'Standard':<18} {'Winner':<12}\")\nprint(\"-\"*70)\n\nfor h in [1, 5, 10, 20]:\n    gate_mse = gate_horizon['obs_mse'].get(h, float('nan'))\n    std_mse = standard_horizon['obs_mse'].get(h, float('nan'))\n    winner = \"Gate-Enhanced\" if gate_mse < std_mse else \"Standard\"\n    print(f\"{h:<10} {gate_mse:<18.6f} {std_mse:<18.6f} {winner:<12}\")\n\nprint(\"-\"*70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "\"\"\"\nCell: Long-Horizon Visualization\nPurpose: Visualize how prediction error grows with horizon\n\"\"\"\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\nhorizons = [1, 5, 10, 20]\n\n# Observation MSE vs Horizon\nax = axes[0]\ngate_obs = [gate_horizon['obs_mse'].get(h, float('nan')) for h in horizons]\nstd_obs = [standard_horizon['obs_mse'].get(h, float('nan')) for h in horizons]\n\nax.plot(horizons, gate_obs, 'o-', color='#9b59b6', linewidth=2, \n        markersize=8, label='Gate-Enhanced')\nax.plot(horizons, std_obs, 's-', color='#3498db', linewidth=2, \n        markersize=8, label='Standard')\nax.set_xlabel('Prediction Horizon (steps)')\nax.set_ylabel('Observation MSE')\nax.set_title('Long-Horizon Observation Prediction')\nax.legend()\nax.grid(True, alpha=0.3)\nax.set_xticks(horizons)\n\n# Reward MSE vs Horizon\nax = axes[1]\ngate_rew = [gate_horizon['reward_mse'].get(h, float('nan')) for h in horizons]\nstd_rew = [standard_horizon['reward_mse'].get(h, float('nan')) for h in horizons]\n\nax.plot(horizons, gate_rew, 'o-', color='#9b59b6', linewidth=2, \n        markersize=8, label='Gate-Enhanced')\nax.plot(horizons, std_rew, 's-', color='#3498db', linewidth=2, \n        markersize=8, label='Standard')\nax.set_xlabel('Prediction Horizon (steps)')\nax.set_ylabel('Reward MSE')\nax.set_title('Long-Horizon Reward Prediction')\nax.legend()\nax.grid(True, alpha=0.3)\nax.set_xticks(horizons)\n\nfig.suptitle('Long-Horizon Prediction: Gate-Enhanced vs Standard', fontsize=12, fontweight='bold')\nplt.tight_layout()\nplt.show()\n\n# Store results\nlong_horizon_results = {\n    'gate_enhanced': gate_horizon,\n    'standard': standard_horizon\n}\nprint(\"\\nLong-horizon results stored for cross-notebook comparison.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating and training model for analysis...\n",
      "Gate Layer Analysis\n",
      "============================================================\n",
      "\n",
      "Encoder Gate Block:\n",
      "\n",
      "  Layer 1:\n",
      "    Hadamard scale - mean: 1.0000, std: 0.0005\n",
      "    Rotation angles - mean: 0.0044, std: 0.1023\n",
      "    CNOT entanglement strength: 0.0776\n",
      "    Phase angles - mean: 0.0015, std: 0.0961\n",
      "\n",
      "  Layer 2:\n",
      "    Hadamard scale - mean: 1.0000, std: 0.0005\n",
      "    Rotation angles - mean: -0.0006, std: 0.1026\n",
      "    CNOT entanglement strength: 0.0796\n",
      "    Phase angles - mean: 0.0028, std: 0.0987\n",
      "\n",
      "RSSM Prior Gate Block:\n",
      "  Layer 1:\n",
      "    CNOT entanglement: 0.0787\n",
      "  Layer 2:\n",
      "    CNOT entanglement: 0.0762\n"
     ]
    }
   ],
   "source": [
    "def analyze_gate_layers(model: GateEnhancedWorldModel):\n",
    "    \"\"\"\n",
    "    Analyze the learned parameters in quantum gate layers.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : GateEnhancedWorldModel\n",
    "        The trained model\n",
    "    \"\"\"\n",
    "    print(\"Gate Layer Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Analyze encoder gate block\n",
    "    print(\"\\nEncoder Gate Block:\")\n",
    "    for i, layer in enumerate(model.encoder.gate_block.layers):\n",
    "        print(f\"\\n  Layer {i+1}:\")\n",
    "        for sublayer in layer:\n",
    "            if isinstance(sublayer, RotationLayer):\n",
    "                angles = sublayer.angles.detach().cpu().numpy()\n",
    "                print(f\"    Rotation angles - mean: {angles.mean():.4f}, std: {angles.std():.4f}\")\n",
    "            elif isinstance(sublayer, CNOTLayer):\n",
    "                entanglement = sublayer.get_entanglement_strength().item()\n",
    "                print(f\"    CNOT entanglement strength: {entanglement:.4f}\")\n",
    "            elif isinstance(sublayer, PhaseLayer):\n",
    "                phases = sublayer.phases.detach().cpu().numpy()\n",
    "                print(f\"    Phase angles - mean: {phases.mean():.4f}, std: {phases.std():.4f}\")\n",
    "            elif isinstance(sublayer, HadamardLayer):\n",
    "                scale = sublayer.scale.detach().cpu().numpy()\n",
    "                print(f\"    Hadamard scale - mean: {scale.mean():.4f}, std: {scale.std():.4f}\")\n",
    "    \n",
    "    # Analyze RSSM gate blocks\n",
    "    print(\"\\nRSSM Prior Gate Block:\")\n",
    "    for i, layer in enumerate(model.rssm.prior_gate.layers):\n",
    "        print(f\"  Layer {i+1}:\")\n",
    "        for sublayer in layer:\n",
    "            if isinstance(sublayer, CNOTLayer):\n",
    "                entanglement = sublayer.get_entanglement_strength().item()\n",
    "                print(f\"    CNOT entanglement: {entanglement:.4f}\")\n",
    "\n",
    "\n",
    "# Run analysis on a trained model\n",
    "print(\"Creating and training model for analysis...\")\n",
    "analysis_model = GateEnhancedWorldModel(obs_dim=4, action_dim=1).to(device)\n",
    "\n",
    "# Quick training\n",
    "trainer = GateEnhancedTrainer(analysis_model)\n",
    "for _ in range(10):\n",
    "    obs = torch.randn(16, 20, 4, device=device)\n",
    "    actions = torch.randn(16, 20, 1, device=device)\n",
    "    rewards = torch.randn(16, 20, device=device)\n",
    "    trainer.train_step(obs, actions, rewards)\n",
    "\n",
    "analyze_gate_layers(analysis_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.15 Summary\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Hadamard Layers**: Create orthogonal feature mixing, preserving information while enabling complex transformations\n",
    "\n",
    "2. **Rotation Layers**: Learn task-specific rotations in feature space, providing flexible parameterized transformations\n",
    "\n",
    "3. **CNOT Layers**: Create controlled dependencies between features, enabling entanglement-like correlations\n",
    "\n",
    "4. **Phase Layers**: Apply learnable phase modulations for additional expressivity\n",
    "\n",
    "### Implementation Notes\n",
    "\n",
    "- All layers preserve dimension and can be stacked\n",
    "- Residual connections improve training stability\n",
    "- The gate-enhanced model has more parameters but offers richer representations\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Phase 6: Error Correction Ensemble\n",
    "- Phase 7: Comprehensive Comparison\n",
    "- Phase 8: Ablation Studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Phase 5: Gate-Enhanced Neural Layers - COMPLETE\n",
      "============================================================\n",
      "\n",
      "Implemented Quantum Gate Layers:\n",
      "  - HadamardLayer: Orthogonal feature mixing\n",
      "  - RotationLayer: Parameterized rotations (Rx, Ry, Rz)\n",
      "  - CNOTLayer: Controlled operations for correlations\n",
      "  - PhaseLayer: Phase modulations\n",
      "  - QuantumGateBlock: Composite quantum circuit-like block\n",
      "  - GateEnhancedWorldModel: Full world model integration\n",
      "\n",
      "Dissertation Metrics Collected:\n",
      "  - Sample Efficiency (epochs to target)\n",
      "  - Training Speed (wall-clock time)\n",
      "  - Prediction Accuracy (test set MSE)\n",
      "  - Final Performance (training loss)\n",
      "  - Stability (standard deviation across seeds)\n",
      "  - Computational Cost (parameter count)\n",
      "\n",
      "Statistical Analysis:\n",
      "  - 5-seed experiments for reproducibility\n",
      "  - Mann-Whitney U tests\n",
      "  - Cohen's d effect sizes\n",
      "  - Bonferroni correction for multiple comparisons\n",
      "  - 95% confidence intervals\n",
      "\n",
      "Ready for Phase 6: Error Correction Ensemble\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Phase 5: Gate-Enhanced Neural Layers - COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nImplemented Quantum Gate Layers:\")\n",
    "print(\"  - HadamardLayer: Orthogonal feature mixing\")\n",
    "print(\"  - RotationLayer: Parameterized rotations (Rx, Ry, Rz)\")\n",
    "print(\"  - CNOTLayer: Controlled operations for correlations\")\n",
    "print(\"  - PhaseLayer: Phase modulations\")\n",
    "print(\"  - QuantumGateBlock: Composite quantum circuit-like block\")\n",
    "print(\"  - GateEnhancedWorldModel: Full world model integration\")\n",
    "print(\"\\nDissertation Metrics Collected:\")\n",
    "print(\"  - Sample Efficiency (epochs to target)\")\n",
    "print(\"  - Training Speed (wall-clock time)\")\n",
    "print(\"  - Prediction Accuracy (test set MSE)\")\n",
    "print(\"  - Final Performance (training loss)\")\n",
    "print(\"  - Stability (standard deviation across seeds)\")\n",
    "print(\"  - Computational Cost (parameter count)\")\n",
    "print(\"\\nStatistical Analysis:\")\n",
    "print(\"  - 5-seed experiments for reproducibility\")\n",
    "print(\"  - Mann-Whitney U tests\")\n",
    "print(\"  - Cohen's d effect sizes\")\n",
    "print(\"  - Bonferroni correction for multiple comparisons\")\n",
    "print(\"  - 95% confidence intervals\")\n",
    "print(\"\\nReady for Phase 6: Error Correction Ensemble\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}